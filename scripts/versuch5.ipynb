{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import json\n",
    "from training_data import generate_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trainingsdaten generieren und extern abspeichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 0, 0, 0, 0, 0, 1, 1, 1], 1)\n"
     ]
    }
   ],
   "source": [
    "training_data = generate_train_data(10, 3) # 10 pixelbilder generieren welche 3X3 pixel gross sind\n",
    "\n",
    "training_data_sample = training_data[0]\n",
    "training_data_sample_target = [1, 0] if training_data[0][1] == 1 else [0, 1]\n",
    "training_data_sample_image = training_data[0][0]\n",
    "\n",
    "print(training_data_sample) # beispiel einer horizontale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainingsdaten in externem file sichern\n",
    "file_path_dt = \"../data/data_train.json\"\n",
    "\n",
    "with open(file_path_dt, \"w\") as file:\n",
    "    json.dump(training_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Netzwerk initialisieren und extern ablegen und schÃ¶n formatiert herausprinten\n",
    "- funktionen definieren\n",
    "- funktionen aufrufen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funktion fÃ¼r fake weights und fake biases eines neurons\n",
    "def init_bias():\n",
    "    bias = random.uniform(-0.5, 0.5)\n",
    "    return bias\n",
    "#print(init_bias())\n",
    "\n",
    "def init_weights(anz_weights):\n",
    "    weights = [random.uniform(-0.5, 0.5) for _ in range(anz_weights)]\n",
    "    return weights\n",
    "#print(init_weights(4))\n",
    "\n",
    "\n",
    "def init_network(dimension):\n",
    "\n",
    "    network = [] # eine liste von listen von dictionaries (jedes neuron wird von einem dicrionary reprÃ¤sentiert)\n",
    "    \n",
    "    # ----- Input layer ----- (hat keine biases oder weights!)\n",
    "    # fÃ¼r jedes layer eine liste machen und diese mit den dictionaries fÃ¼llen\n",
    "    for layer in dimension[:1]: # nur fÃ¼r die input layers\n",
    "        network.append([\n",
    "            {\n",
    "                \"weights\":None, \n",
    "                \"bias\":None, \n",
    "                \"activation\":None, \n",
    "                \"error\": None\n",
    "            } for _ in range(layer)\n",
    "        ]) # liste mit leeren dictionaries hinzufÃ¼gen fÃ¼r jedes neuron des inputlayers\n",
    "\n",
    "    # ----- Hidden layers -----\n",
    "    # FÃ¼r jedes Hidden-Layer eine Liste mit Dictionaries hinzufÃ¼gen, diese haben weights und biases\n",
    "    for index, layer in enumerate(dimension[1:-1], start=1):  # i startet bei 1, weil wir ab der 2. Schicht zÃ¤hlen\n",
    "        network.append([\n",
    "        {\n",
    "            \"weights\": init_weights(dimension[index - 1]),  # Anzahl Gewichte = Anz. Neuronen im vorherigen Layer\n",
    "            \"bias\": init_bias(),\n",
    "            \"activation\": None, \n",
    "            \"error\": None\n",
    "        } for _ in range(layer)  # Anzahl Neuronen in der aktuellen Schicht\n",
    "    ])\n",
    "        \n",
    "    # ----- Output layer -----\n",
    "    # FÃ¼r das otput Layer eine Liste mit Dictionaries hinzufÃ¼gen, diese haben weights und biases\n",
    "    for index, layer in enumerate(dimension[-1:], start=-1):  # i startet bei 1, weil wir ab der 2. Schicht zÃ¤hlen\n",
    "        network.append([\n",
    "        {\n",
    "            \"weights\": init_weights(dimension[index - 1]),  # Anzahl Gewichte = Anz. Neuronen im vorherigen Layer\n",
    "            \"bias\": init_bias(),\n",
    "            \"activation\": None, \n",
    "            \"error\": None\n",
    "        } for _ in range(layer)  # Anzahl Neuronen in der aktuellen Schicht\n",
    "    ])\n",
    "    return network\n",
    "#print(init_network([9, 5, 5, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------- Netzwerk (v.1) vor der Forward-Propagation mit initialisierten b, w -------------------\n",
      "\n",
      "ðŸ”¹ Ebene 0:\n",
      "  â–ª Element 0: {'weights': None, 'bias': None, 'activation': None, 'target_activation': None, 'error': None}\n",
      "  â–ª Element 1: {'weights': None, 'bias': None, 'activation': None, 'target_activation': None, 'error': None}\n",
      "  â–ª Element 2: {'weights': None, 'bias': None, 'activation': None, 'target_activation': None, 'error': None}\n",
      "  â–ª Element 3: {'weights': None, 'bias': None, 'activation': None, 'target_activation': None, 'error': None}\n",
      "  â–ª Element 4: {'weights': None, 'bias': None, 'activation': None, 'target_activation': None, 'error': None}\n",
      "  â–ª Element 5: {'weights': None, 'bias': None, 'activation': None, 'target_activation': None, 'error': None}\n",
      "  â–ª Element 6: {'weights': None, 'bias': None, 'activation': None, 'target_activation': None, 'error': None}\n",
      "  â–ª Element 7: {'weights': None, 'bias': None, 'activation': None, 'target_activation': None, 'error': None}\n",
      "  â–ª Element 8: {'weights': None, 'bias': None, 'activation': None, 'target_activation': None, 'error': None}\n",
      "\n",
      "\n",
      "ðŸ”¹ Ebene 1:\n",
      "  â–ª Element 0: {'weights': [-0.20575823848116392, 0.2201043214747186, -0.21695264882232124, 0.16565075557855768, 0.09788478079093976, -0.3936763251351326, -0.49508420608050885, -0.3665145696500822, 0.15000202079047686], 'bias': 0.35248515051710183, 'activation': None, 'target_activation': None, 'error': None}\n",
      "  â–ª Element 1: {'weights': [0.05524884492423865, -0.45869456404453557, 0.365216121884964, 0.09094517639455435, 0.21410396473886006, 0.02616875350609993, 0.08628237947481099, 0.1949082778283452, -0.2658908456268244], 'bias': 0.3617651395243815, 'activation': None, 'target_activation': None, 'error': None}\n",
      "  â–ª Element 2: {'weights': [0.16647946464775853, 0.31473075970805475, 0.4577689717150836, -0.08812716317423963, -0.25676616776267136, -0.14190008683929445, 0.4219094680204968, -0.16697687564848218, -0.00402878381359717], 'bias': -0.40101905211295064, 'activation': None, 'target_activation': None, 'error': None}\n",
      "  â–ª Element 3: {'weights': [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701], 'bias': -0.4498036763391735, 'activation': None, 'target_activation': None, 'error': None}\n",
      "  â–ª Element 4: {'weights': [-0.051873464806236225, 0.10464263794059225, -0.37735054204590013, 0.27568592802976144, -0.45666659825833944, -0.4581621809729136, 0.2399866001508142, 0.4184937033361027, 0.3294732612902822], 'bias': -0.3097403323387301, 'activation': None, 'target_activation': None, 'error': None}\n",
      "\n",
      "\n",
      "ðŸ”¹ Ebene 2:\n",
      "  â–ª Element 0: {'weights': [0.2781435462194367, -0.4869195543356437, 0.432707693341323, 0.10930524983705137, 0.004321434274387692], 'bias': 0.42000886539078, 'activation': None, 'target_activation': None, 'error': None}\n",
      "  â–ª Element 1: {'weights': [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852], 'bias': -0.39195604157641695, 'activation': None, 'target_activation': None, 'error': None}\n",
      "  â–ª Element 2: {'weights': [0.4573580882298527, -0.2849251968314791, -0.15791731879017767, 0.08143634535064503, -0.47251616358203674], 'bias': 0.3567979477033839, 'activation': None, 'target_activation': None, 'error': None}\n",
      "  â–ª Element 3: {'weights': [0.005656180241009889, -0.05288807326375866, -0.15337363616658328, 0.26904289757018296, -0.010367959723265985], 'bias': 0.3834499349685605, 'activation': None, 'target_activation': None, 'error': None}\n",
      "  â–ª Element 4: {'weights': [-0.44608800966632345, -0.374971423655744, 0.43136805246346466, -0.463730136074775, -0.0267059718381083], 'bias': 0.2676336062123419, 'activation': None, 'target_activation': None, 'error': None}\n",
      "\n",
      "\n",
      "ðŸ”¹ Ebene 3:\n",
      "  â–ª Element 0: {'weights': [0.3040350051877949, 0.362933057353379, 0.17230101454862534, -0.4152678717476682, -0.4217020525645335], 'bias': -0.15625408839192734, 'activation': None, 'target_activation': None, 'error': None}\n",
      "  â–ª Element 1: {'weights': [-0.4119681030297825, -0.05830109053717403, 0.36087237216399637, -0.2212145500596937, 0.21354452004835478], 'bias': -0.29033269689943275, 'activation': None, 'target_activation': None, 'error': None}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network_dimension = [9, 5, 5, 2]\n",
    "\n",
    "network_i = init_network(network_dimension) # netzerkt nach dem n-1 ten durchlauf\n",
    "\n",
    "# funktion um das netzwerk schÃ¶ner darzustellen\n",
    "def print_array_structure(array):\n",
    "    for i, layer in enumerate(array):\n",
    "        print(f\"ðŸ”¹ Ebene {i}:\")\n",
    "        for j, element in enumerate(layer):\n",
    "            print(f\"  â–ª Element {j}: {{'weights': {element[\"weights\"]}, 'bias': {element['bias']}, 'activation': {element['activation']}, 'target_activation': {element['activation']}, 'error': {element['error']}}}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "print(f\"\\n------------------- Netzwerk (v.1) vor der Forward-Propagation mit initialisierten b, w -------------------\\n\")\n",
    "print_array_structure(network_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisiertes model \"network_i\" in das file \"netzwerk_initialized\" speichern\n",
    "file_path_ni = \"../model/netzwerk_initialized.json\"\n",
    "\n",
    "with open(file_path_ni, \"w\") as file:\n",
    "    json.dump(network_i, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## forward propagation\n",
    "- aktivierungsfunktionen\n",
    "- forward-propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6590011388859679\n"
     ]
    }
   ],
   "source": [
    "# aktivierungsfunktionen\n",
    "\n",
    "def activation_relu(x): # hidden layers (werden hier die resultate nicht immer mit jedem layer hÃ¶her?)\n",
    "    return max(0, x)\n",
    "\n",
    "def softmax(x, x_list): # output layer\n",
    "    x_list = [math.exp(i) for i in x_list]\n",
    "    return math.exp(x) / sum(x_list)\n",
    "\n",
    "print(softmax(2.0, [2.0, 1.0, 0.1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------- Netzwerk (v.2) nach der Forward-Propagation mit initialisierten a -------------------\n",
      "\n",
      "ðŸ”¹ Ebene 0:\n",
      "  â–ª Element 0: {'weights': None, 'bias': None, 'activation': 0, 'target_activation': 0, 'error': None}\n",
      "  â–ª Element 1: {'weights': None, 'bias': None, 'activation': 0, 'target_activation': 0, 'error': None}\n",
      "  â–ª Element 2: {'weights': None, 'bias': None, 'activation': 0, 'target_activation': 0, 'error': None}\n",
      "  â–ª Element 3: {'weights': None, 'bias': None, 'activation': 0, 'target_activation': 0, 'error': None}\n",
      "  â–ª Element 4: {'weights': None, 'bias': None, 'activation': 0, 'target_activation': 0, 'error': None}\n",
      "  â–ª Element 5: {'weights': None, 'bias': None, 'activation': 0, 'target_activation': 0, 'error': None}\n",
      "  â–ª Element 6: {'weights': None, 'bias': None, 'activation': 1, 'target_activation': 1, 'error': None}\n",
      "  â–ª Element 7: {'weights': None, 'bias': None, 'activation': 1, 'target_activation': 1, 'error': None}\n",
      "  â–ª Element 8: {'weights': None, 'bias': None, 'activation': 1, 'target_activation': 1, 'error': None}\n",
      "\n",
      "\n",
      "ðŸ”¹ Ebene 1:\n",
      "  â–ª Element 0: {'weights': [-0.20575823848116392, 0.2201043214747186, -0.21695264882232124, 0.16565075557855768, 0.09788478079093976, -0.3936763251351326, -0.49508420608050885, -0.3665145696500822, 0.15000202079047686], 'bias': 0.35248515051710183, 'activation': 0, 'target_activation': 0, 'error': None}\n",
      "  â–ª Element 1: {'weights': [0.05524884492423865, -0.45869456404453557, 0.365216121884964, 0.09094517639455435, 0.21410396473886006, 0.02616875350609993, 0.08628237947481099, 0.1949082778283452, -0.2658908456268244], 'bias': 0.3617651395243815, 'activation': 0.37706495120071326, 'target_activation': 0.37706495120071326, 'error': None}\n",
      "  â–ª Element 2: {'weights': [0.16647946464775853, 0.31473075970805475, 0.4577689717150836, -0.08812716317423963, -0.25676616776267136, -0.14190008683929445, 0.4219094680204968, -0.16697687564848218, -0.00402878381359717], 'bias': -0.40101905211295064, 'activation': 0, 'target_activation': 0, 'error': None}\n",
      "  â–ª Element 3: {'weights': [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701], 'bias': -0.4498036763391735, 'activation': 0, 'target_activation': 0, 'error': None}\n",
      "  â–ª Element 4: {'weights': [-0.051873464806236225, 0.10464263794059225, -0.37735054204590013, 0.27568592802976144, -0.45666659825833944, -0.4581621809729136, 0.2399866001508142, 0.4184937033361027, 0.3294732612902822], 'bias': -0.3097403323387301, 'activation': 0.678213232438469, 'target_activation': 0.678213232438469, 'error': None}\n",
      "\n",
      "\n",
      "ðŸ”¹ Ebene 2:\n",
      "  â–ª Element 0: {'weights': [0.2781435462194367, -0.4869195543356437, 0.432707693341323, 0.10930524983705137, 0.004321434274387692], 'bias': 0.42000886539078, 'activation': 0.2393394213045403, 'target_activation': 0.2393394213045403, 'error': None}\n",
      "  â–ª Element 1: {'weights': [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852], 'bias': -0.39195604157641695, 'activation': 0, 'target_activation': 0, 'error': None}\n",
      "  â–ª Element 2: {'weights': [0.4573580882298527, -0.2849251968314791, -0.15791731879017767, 0.08143634535064503, -0.47251616358203674], 'bias': 0.3567979477033839, 'activation': 0, 'target_activation': 0, 'error': None}\n",
      "  â–ª Element 3: {'weights': [0.005656180241009889, -0.05288807326375866, -0.15337363616658328, 0.26904289757018296, -0.010367959723265985], 'bias': 0.3834499349685605, 'activation': 0.3564760087265535, 'target_activation': 0.3564760087265535, 'error': None}\n",
      "  â–ª Element 4: {'weights': [-0.44608800966632345, -0.374971423655744, 0.43136805246346466, -0.463730136074775, -0.0267059718381083], 'bias': 0.2676336062123419, 'activation': 0.10813268116419267, 'target_activation': 0.10813268116419267, 'error': None}\n",
      "\n",
      "\n",
      "ðŸ”¹ Ebene 3:\n",
      "  â–ª Element 0: {'weights': [0.3040350051877949, 0.362933057353379, 0.17230101454862534, -0.4152678717476682, -0.4217020525645335], 'bias': -0.15625408839192734, 'activation': 0.541797256745285, 'target_activation': 0.541797256745285, 'error': None}\n",
      "  â–ª Element 1: {'weights': [-0.4119681030297825, -0.05830109053717403, 0.36087237216399637, -0.2212145500596937, 0.21354452004835478], 'bias': -0.29033269689943275, 'activation': 0.4582027432547151, 'target_activation': 0.4582027432547151, 'error': None}\n",
      "\n",
      "\n",
      "Outputs des letzten Layers: [0.541797256745285, 0.4582027432547151]\n"
     ]
    }
   ],
   "source": [
    "# forwardpropagation\n",
    "\n",
    "def forward_propagation(pixel_bild, netzwerk): # im pronzip fÃ¼llt diese fuktion das feld \"activation\" des dictinaries!\n",
    "\n",
    "    new_network = netzwerk\n",
    "\n",
    "    # INPUT-LAYER: den inputwert des inputlayers als activation setzen\n",
    "    for neuron in range(network_dimension[0]):\n",
    "        new_network[0][neuron][\"activation\"] = pixel_bild[neuron] \n",
    "\n",
    "    # HIDDEN-LAYERS und OUTPUT-LAYER: die informationen n-ten layers werden ans n+1-ten layer weitergegeben (fÃ¼r das letzte layer muss eine sigmoid-funktin verwendet werden damit man die klassifiezierung so durchfÃ¼hren kann dass  nÃ¤her bei 1 oder nÃ¤her bei 0 aufteilen kann)\n",
    "    for n in range(1, len(new_network)):\n",
    "        outputs = []\n",
    "\n",
    "        # folgendes wird fÃ¼r jedes neuron eines layers gemacht\n",
    "        for neuron in range(network_dimension[n]):\n",
    "            prev_activations = [new_network[n-1][i][\"activation\"] for i in range(network_dimension[n-1])] # liste mit activations des vorherigen layers\n",
    "            akt_weights = new_network[n][neuron][\"weights\"] # liste mit den weights eines neurons des 2ten layers\n",
    "            akt_bias = new_network[n][neuron][\"bias\"]\n",
    "            \n",
    "            # output-layer\n",
    "            if n == len(new_network)-1:\n",
    "                outputs.append(sum([prev_activations[x] * akt_weights[x] for x in range(len(prev_activations))]) + akt_bias)\n",
    "                if neuron == network_dimension[n]-1:\n",
    "                    pixel_updated_output = [softmax(outputs[output], outputs) for output in range((network_dimension[n]))]\n",
    "                    for sm in range(len(pixel_updated_output)):\n",
    "                        new_network[n][sm][\"activation\"] = pixel_updated_output[sm] # summe aller activations aus dem letzen layer  \n",
    "            \n",
    "            # alle anderen hidden layers\n",
    "            else:\n",
    "                pixel_updated = activation_relu(sum([prev_activations[x] * akt_weights[x] for x in range(len(prev_activations))]) + akt_bias)\n",
    "                new_network[n][neuron][\"activation\"] = pixel_updated # summe aller activations aus dem letzen layer  \n",
    "\n",
    "    return new_network, [node[\"activation\"] for node in new_network[-1]] # mit pixelbild ist hier der semantsche vektor des letzen layers gemeint, also der activations des letzen layers\n",
    "\n",
    "network_f = forward_propagation(training_data_sample[0], network_i)[0]\n",
    "outputs_f = forward_propagation(training_data_sample[0], network_i)[1]\n",
    "\n",
    "print(f\"\\n------------------- Netzwerk (v.2) nach der Forward-Propagation mit initialisierten a -------------------\\n\")\n",
    "print_array_structure(network_f)\n",
    "print(f\"Outputs des letzten Layers: {outputs_f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction machen\n",
    "prediction:\n",
    "um eine prediction zu machen muss man einfach den output des letzen layers analysiern!\n",
    "cross-entropy funktion:\n",
    "um eine prediction zu machen beweten einen input mit der forwardprop durch das netz laufen lassen und die abweichung zu mtarget wert berechnen. bei einer prdiction muss nicht heissen dass das model auch automatisch triniert wird. aber ich mache es so dass jedes mal wo das model trainiert wird auch noch eine prediction berechnet wird um zu sehen wie sich das model verbessert hat! die prediction berechnet man mit der loss funktion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertikal\n"
     ]
    }
   ],
   "source": [
    "# diese fuktion fÃ¤sst das resultat des letzen layers in worte\n",
    "# der netzwerk_output ist immer eine liste von wahrscheinlichkeiten die zusammen 1 ergeben (softmax), die erste wk steht fÃ¼r horizontal und die zweite steht fÃ¼r vertikal. die die hÃ¶her ist ist das resuotat!\n",
    "def predict(network_output):\n",
    "    if network_output[0]+network_output[1] != 1:\n",
    "        return \"Die Prediction hat eine komische Form und ergibt nicht 1 in der Summe!\"\n",
    "    if network_output[0] == network_output[1]:\n",
    "        return \"Die prediction ist bei beide gleich gross!\"\n",
    "\n",
    "    max_pred = max(network_output)\n",
    "    for index, pred in enumerate(network_output):\n",
    "        if pred == max_pred:\n",
    "            prediction = \"horizontal\" if index == 0 else \"vertikal\"\n",
    "    return prediction\n",
    "\n",
    "print(predict([0.2, 0.8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "attachments": {
    "41d55c0f-d1ed-420e-9090-d701fe6352e8.png": {
     "image/png": "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"
    },
    "8d085fb2-d880-4361-ae32-4cbbd1250bdd.png": {
     "image/png": "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"
    },
    "c6bfdb5a-1673-4146-b292-418b25facdf1.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**loss funktion:** \n",
    "warum ein log? fÃ¼r kleine werte (tiefe wks) gibt es grosse outputs! das heisst dass fÃ¼r eine kleine WK wie 0.1 ein grosser fehler berechnet wird! (das sorgt dafÃ¼r dasss die back-prop nicht nur fÃ¼r die momentanen resultate optimiet sondern such fÃ¼r vergangene)\n",
    "\n",
    "![image.png](attachment:image.png) ![loss-funktion](../loss_funktion_ableitung.jpg)\n",
    "\n",
    "![image.png](attachment:8d085fb2-d880-4361-ae32-4cbbd1250bdd.png)![image.png](attachment:c6bfdb5a-1673-4146-b292-418b25facdf1.png)\n",
    "\n",
    "**gradient descent:**\n",
    "\n",
    "was macht gradient descent = es berechnet fÃ¼r das aktuelle neuron das neu gewicht!\n",
    "\n",
    "was ist ein gradient?\n",
    "- ein gradients ist eine menge (liste) von partiellen ableitungen. wenn man eine funktion f(x, y, z) ableitet bekommt man 3 partielle abletungen, eine fÃ¼r x, y, z! hier kann man x, y, z als die verschiedenen weigts sehen oder vilmehr ihre faktoren !\n",
    "- den partiellen gradient berechnet man fÃ¼r jedes gewicht eines neurons, dieser gradient sagt uns dann wie stark dieses gewicht zum loss beigetragen hat!\n",
    "\n",
    "   - a = lernrate, so stark werden die gewichte verÃ¤ndert (werte zwischen 0.001 und 0.01)\n",
    "   - gradient (ableitung) = aprev * error = bringt variatÃ¤t hinein damit alle neuronen der selben schicht nicht gleich sind. da sie bei der berechnung der aktuellen activation mit den weights multipliziert wurden habe sie bestimmt wie stark das weigth einfluss auf den error hatte, es ist also ein einflussfaktor bei der berechnung des errors (ich verwende hier die vereinfachte variante!)\n",
    "   - w = das letzte weight muss auch noch miteinfliessen damit das model nicht komplett neu Ã¼berschrieben wird! wenn neue gewichte entstehen passiert das immer nter berÃ¼cksichtigung der alten gewichte!\n",
    "\n",
    "![image.png](attachment:41d55c0f-d1ed-420e-9090-d701fe6352e8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0\n",
      "0.10536051565782628\n"
     ]
    }
   ],
   "source": [
    "# funktionen\n",
    "\n",
    "# der output ist eine zahl fÃ¼r ein layer: den error fÃ¼r das gesamte outputlayer berechnen (das braucht man nur um zu messen wie gut das modell!)\n",
    "def cross_entropy_loss(predictions, targets):\n",
    "    \n",
    "    epsilon = 1e-15  # Kleiner Wert, um log(0) zu vermeiden\n",
    "    predictions = [max(p, epsilon) for p in predictions]  # Verhindert log(0)\n",
    "    \n",
    "    return -sum(tar * math.log(pred) for pred, tar in zip(predictions, targets)) # mathematische formel fÃ¼r das loss\n",
    "\n",
    "def calc_error(pred, target):\n",
    "    return target - pred\n",
    "\n",
    "\n",
    "print(cross_entropy_loss([1, 0], [1, 0])) # der loss ist nicht null wenn es dem target entspricht sondern wenn 100% zu 0% steht!\n",
    "print(cross_entropy_loss([0.9, 0.1], [1, 0])) # ein sehr geringes loss fÃ¼r eine sehr gute prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funktionen fÃ¼r die backpropagation\n",
    "\n",
    "# lossfunktion um das loss ienes einzelnen neurons zu berechnen mithilfe der weigths\n",
    "def calc_gradients(a_func, a, prev_activations, p_target):\n",
    "\n",
    "    new_weights = []\n",
    "    if a_func == \"relu\":\n",
    "        a_ableitung = 1 if a > 0 else 0\n",
    "        \n",
    "    else:\n",
    "        a_ableitung = a * (1 - a)\n",
    "    \n",
    "    # fÃ¼r jedes weights die ableitung berechnen\n",
    "    for activation in prev_activations:\n",
    "        # new_weight = -1 * p_target * 1 / weight * activation # das ist die berechnung zur ableitung eines weights (weil die anderen weights als parameter betrachtet werden kÃ¶nnen die wie konstanten beim ableiten einfach weggestrichen werden! Achtung man muss die ableitung der aktivierungsfunktion auch berÃ¼cksichtigen!)\n",
    "        new_weight = p_target * a_ableitung * a # das ist die berechnung zur ableitung eines weights (weil die anderen weights als parameter betrachtet werden kÃ¶nnen die wie konstanten beim ableiten einfach weggestrichen werden! Achtung man muss die ableitung der aktivierungsfunktion auch berÃ¼cksichtigen!)\n",
    "        new_weights.append(new_weight)\n",
    "    \n",
    "    return new_weights\n",
    "\n",
    "\n",
    "def calc_new_weight(old_weight, learning_rate, gradient):\n",
    "    new_weight = old_weight - learning_rate * gradient\n",
    "    return new_weight\n",
    "\n",
    "\n",
    "def calc_target_a(next_errors, next_weights, a):\n",
    "    error_sum = sum(next_errors[i]*next_weights[i] for i in range(len(next_errors)))\n",
    "                    \n",
    "    # ableitung der aktivierungsfunktion (relu) der hidden layers berechnen da diese funktion nur bei den hidden layers angewendet wird\n",
    "    a_derivative = 1 if a > 0 else 0\n",
    "\n",
    "    a_target = error_sum * a_derivative\n",
    "\n",
    "    return a_target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy Loss des Output layers: 0.7804435219559693\n",
      "\n",
      " ---------- Layer 3 ---------- \n",
      "\n",
      "Error: -0.541797256745285\n",
      "Gradients of neuron Nr.0: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [0.3040350051877949, 0.362933057353379, 0.17230101454862534, -0.4152678717476682, -0.4217020525645335] werden mit den weights [0.3040350051877949, 0.362933057353379, 0.17230101454862534, -0.4152678717476682, -0.4217020525645335] ersetzt!\n",
      "der Bias: -0.15625408839192734 wird mit -0.15083611582447448 ersetzt!\n",
      "Error: 0.5417972567452849\n",
      "Gradients of neuron Nr.1: [0.1137502007315337, 0.1137502007315337, 0.1137502007315337, 0.1137502007315337, 0.1137502007315337]\n",
      "Die weights: [-0.4119681030297825, -0.05830109053717403, 0.36087237216399637, -0.2212145500596937, 0.21354452004835478] werden mit den weights [-0.4131056050370978, -0.05943859254448936, 0.35973487015668104, -0.22235205206700903, 0.21240701804103945] ersetzt!\n",
      "der Bias: -0.29033269689943275 wird mit -0.2957506694668856 ersetzt!\n",
      "\n",
      " ---------- Layer 2 ---------- \n",
      "\n",
      "Error: -0.6278842366250268\n",
      "Gradients of neuron Nr.0: [-0.016930138108597812, -0.016930138108597812, -0.016930138108597812, -0.016930138108597812, -0.016930138108597812]\n",
      "Die weights: [0.2781435462194367, -0.4869195543356437, 0.432707693341323, 0.10930524983705137, 0.004321434274387692] werden mit den weights [0.27831284760052266, -0.48675025295455776, 0.4328769947224089, 0.10947455121813734, 0.00449073565547367] ersetzt!\n",
      "der Bias: 0.42000886539078 wird mit 0.42628770775703023 ersetzt!\n",
      "Error: -0.0\n",
      "Gradients of neuron Nr.1: [-0.0, -0.0, -0.0, -0.0, -0.0]\n",
      "Die weights: [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852] werden mit den weights [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852] ersetzt!\n",
      "der Bias: -0.39195604157641695 wird mit -0.39195604157641695 ersetzt!\n",
      "Error: 0.0\n",
      "Gradients of neuron Nr.2: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [0.4573580882298527, -0.2849251968314791, -0.15791731879017767, 0.08143634535064503, -0.47251616358203674] werden mit den weights [0.4573580882298527, -0.2849251968314791, -0.15791731879017767, 0.08143634535064503, -0.47251616358203674] ersetzt!\n",
      "der Bias: 0.3567979477033839 wird mit 0.3567979477033839 ersetzt!\n",
      "Error: -0.25195474684080427\n",
      "Gradients of neuron Nr.3: [0.008547320716790107, 0.008547320716790107, 0.008547320716790107, 0.008547320716790107, 0.008547320716790107]\n",
      "Die weights: [0.005656180241009889, -0.05288807326375866, -0.15337363616658328, 0.26904289757018296, -0.010367959723265985] werden mit den weights [0.0055707070338419885, -0.052973546470926565, -0.15345910937375118, 0.26895742436301506, -0.010453432930433887] ersetzt!\n",
      "der Bias: 0.3834499349685605 wird mit 0.38596948243696855 ersetzt!\n",
      "Error: 0.23542587376720897\n",
      "Gradients of neuron Nr.4: [0.0035827372613321845, 0.0035827372613321845, 0.0035827372613321845, 0.0035827372613321845, 0.0035827372613321845]\n",
      "Die weights: [-0.44608800966632345, -0.374971423655744, 0.43136805246346466, -0.463730136074775, -0.0267059718381083] werden mit den weights [-0.44612383703893677, -0.3750072510283573, 0.43133222509085134, -0.4637659634473883, -0.02674179921072162] ersetzt!\n",
      "der Bias: 0.2676336062123419 wird mit 0.2652793474746698 ersetzt!\n",
      "\n",
      " ---------- Layer 1 ---------- \n",
      "\n",
      "Error: -0.0\n",
      "Gradients of neuron Nr.0: [-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0]\n",
      "Die weights: [-0.20575823848116392, 0.2201043214747186, -0.21695264882232124, 0.16565075557855768, 0.09788478079093976, -0.3936763251351326, -0.49508420608050885, -0.3665145696500822, 0.15000202079047686] werden mit den weights [-0.20575823848116392, 0.2201043214747186, -0.21695264882232124, 0.16565075557855768, 0.09788478079093976, -0.3936763251351326, -0.49508420608050885, -0.3665145696500822, 0.15000202079047686] ersetzt!\n",
      "der Bias: 0.35248515051710183 wird mit 0.35248515051710183 ersetzt!\n",
      "Error: -0.14638161344935025\n",
      "Gradients of neuron Nr.1: [0.02043108003569033, 0.02043108003569033, 0.02043108003569033, 0.02043108003569033, 0.02043108003569033, 0.02043108003569033, 0.02043108003569033, 0.02043108003569033, 0.02043108003569033]\n",
      "Die weights: [0.05524884492423865, -0.45869456404453557, 0.365216121884964, 0.09094517639455435, 0.21410396473886006, 0.02616875350609993, 0.08628237947481099, 0.1949082778283452, -0.2658908456268244] werden mit den weights [0.055044534123881744, -0.45889887484489245, 0.3650118110846071, 0.09074086559419745, 0.21389965393850316, 0.025964442705743024, 0.08607806867445408, 0.19470396702798828, -0.2660951564271813] ersetzt!\n",
      "der Bias: 0.3617651395243815 wird mit 0.363228955658875 ersetzt!\n",
      "Error: -0.0\n",
      "Gradients of neuron Nr.2: [-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0]\n",
      "Die weights: [0.16647946464775853, 0.31473075970805475, 0.4577689717150836, -0.08812716317423963, -0.25676616776267136, -0.14190008683929445, 0.4219094680204968, -0.16697687564848218, -0.00402878381359717] werden mit den weights [0.16647946464775853, 0.31473075970805475, 0.4577689717150836, -0.08812716317423963, -0.25676616776267136, -0.14190008683929445, 0.4219094680204968, -0.16697687564848218, -0.00402878381359717] ersetzt!\n",
      "der Bias: -0.40101905211295064 wird mit -0.40101905211295064 ersetzt!\n",
      "Error: -0.0\n",
      "Gradients of neuron Nr.3: [-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0]\n",
      "Die weights: [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701] werden mit den weights [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701] ersetzt!\n",
      "der Bias: -0.4498036763391735 wird mit -0.4498036763391735 ersetzt!\n",
      "Error: -0.6846948139650775\n",
      "Gradients of neuron Nr.4: [-0.0009593601772625976, -0.0009593601772625976, -0.0009593601772625976, -0.0009593601772625976, -0.0009593601772625976, -0.0009593601772625976, -0.0009593601772625976, -0.0009593601772625976, -0.0009593601772625976]\n",
      "Die weights: [-0.051873464806236225, 0.10464263794059225, -0.37735054204590013, 0.27568592802976144, -0.45666659825833944, -0.4581621809729136, 0.2399866001508142, 0.4184937033361027, 0.3294732612902822] werden mit den weights [-0.0518638712044636, 0.10465223154236487, -0.3773409484441275, 0.27569552163153405, -0.45665700465656683, -0.458152587371141, 0.23999619375258682, 0.4185032969378753, 0.3294828548920548] ersetzt!\n",
      "der Bias: -0.3097403323387301 wird mit -0.30289338419907935 ersetzt!\n",
      "\n",
      " ---------- Layer 0 ---------- \n",
      "\n",
      "\n",
      "------------------- Netzwerk (v.3) nach der Backward-Propagation mit verÃ¤nderten w, b -------------------\n",
      "\n",
      "ðŸ”¹ Ebene 0:\n",
      "  â–ª Element 0: {'weights': None, 'bias': None, 'activation': 0, 'target_activation': 0, 'error': None}\n",
      "  â–ª Element 1: {'weights': None, 'bias': None, 'activation': 0, 'target_activation': 0, 'error': None}\n",
      "  â–ª Element 2: {'weights': None, 'bias': None, 'activation': 0, 'target_activation': 0, 'error': None}\n",
      "  â–ª Element 3: {'weights': None, 'bias': None, 'activation': 0, 'target_activation': 0, 'error': None}\n",
      "  â–ª Element 4: {'weights': None, 'bias': None, 'activation': 0, 'target_activation': 0, 'error': None}\n",
      "  â–ª Element 5: {'weights': None, 'bias': None, 'activation': 0, 'target_activation': 0, 'error': None}\n",
      "  â–ª Element 6: {'weights': None, 'bias': None, 'activation': 1, 'target_activation': 1, 'error': None}\n",
      "  â–ª Element 7: {'weights': None, 'bias': None, 'activation': 1, 'target_activation': 1, 'error': None}\n",
      "  â–ª Element 8: {'weights': None, 'bias': None, 'activation': 1, 'target_activation': 1, 'error': None}\n",
      "\n",
      "\n",
      "ðŸ”¹ Ebene 1:\n",
      "  â–ª Element 0: {'weights': [-0.20575823848116392, 0.2201043214747186, -0.21695264882232124, 0.16565075557855768, 0.09788478079093976, -0.3936763251351326, -0.49508420608050885, -0.3665145696500822, 0.15000202079047686], 'bias': 0.35248515051710183, 'activation': 0, 'target_activation': 0, 'error': -0.0}\n",
      "  â–ª Element 1: {'weights': [0.055044534123881744, -0.45889887484489245, 0.3650118110846071, 0.09074086559419745, 0.21389965393850316, 0.025964442705743024, 0.08607806867445408, 0.19470396702798828, -0.2660951564271813], 'bias': 0.3617651395243815, 'activation': 0.37706495120071326, 'target_activation': 0.37706495120071326, 'error': -0.14638161344935025}\n",
      "  â–ª Element 2: {'weights': [0.16647946464775853, 0.31473075970805475, 0.4577689717150836, -0.08812716317423963, -0.25676616776267136, -0.14190008683929445, 0.4219094680204968, -0.16697687564848218, -0.00402878381359717], 'bias': -0.40101905211295064, 'activation': 0, 'target_activation': 0, 'error': -0.0}\n",
      "  â–ª Element 3: {'weights': [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701], 'bias': -0.4498036763391735, 'activation': 0, 'target_activation': 0, 'error': -0.0}\n",
      "  â–ª Element 4: {'weights': [-0.0518638712044636, 0.10465223154236487, -0.3773409484441275, 0.27569552163153405, -0.45665700465656683, -0.458152587371141, 0.23999619375258682, 0.4185032969378753, 0.3294828548920548], 'bias': -0.3097403323387301, 'activation': 0.678213232438469, 'target_activation': 0.678213232438469, 'error': -0.6846948139650775}\n",
      "\n",
      "\n",
      "ðŸ”¹ Ebene 2:\n",
      "  â–ª Element 0: {'weights': [0.27831284760052266, -0.48675025295455776, 0.4328769947224089, 0.10947455121813734, 0.00449073565547367], 'bias': 0.42000886539078, 'activation': 0.2393394213045403, 'target_activation': 0.2393394213045403, 'error': -0.6278842366250268}\n",
      "  â–ª Element 1: {'weights': [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852], 'bias': -0.39195604157641695, 'activation': 0, 'target_activation': 0, 'error': -0.0}\n",
      "  â–ª Element 2: {'weights': [0.4573580882298527, -0.2849251968314791, -0.15791731879017767, 0.08143634535064503, -0.47251616358203674], 'bias': 0.3567979477033839, 'activation': 0, 'target_activation': 0, 'error': 0.0}\n",
      "  â–ª Element 3: {'weights': [0.0055707070338419885, -0.052973546470926565, -0.15345910937375118, 0.26895742436301506, -0.010453432930433887], 'bias': 0.3834499349685605, 'activation': 0.3564760087265535, 'target_activation': 0.3564760087265535, 'error': -0.25195474684080427}\n",
      "  â–ª Element 4: {'weights': [-0.44612383703893677, -0.3750072510283573, 0.43133222509085134, -0.4637659634473883, -0.02674179921072162], 'bias': 0.2676336062123419, 'activation': 0.10813268116419267, 'target_activation': 0.10813268116419267, 'error': 0.23542587376720897}\n",
      "\n",
      "\n",
      "ðŸ”¹ Ebene 3:\n",
      "  â–ª Element 0: {'weights': [0.3040350051877949, 0.362933057353379, 0.17230101454862534, -0.4152678717476682, -0.4217020525645335], 'bias': -0.15625408839192734, 'activation': 0.541797256745285, 'target_activation': 0.541797256745285, 'error': -0.541797256745285}\n",
      "  â–ª Element 1: {'weights': [-0.4131056050370978, -0.05943859254448936, 0.35973487015668104, -0.22235205206700903, 0.21240701804103945], 'bias': -0.29033269689943275, 'activation': 0.4582027432547151, 'target_activation': 0.4582027432547151, 'error': 0.5417972567452849}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# backpropagation\n",
    "def backprop(netzwerk, target, lr):\n",
    "\n",
    "    network_b = netzwerk\n",
    "\n",
    "    # LOSS fÃ¼rs gesamte layer. wie gut ist das modell? (LOSS fÃ¼r das letzte layer berechnen)\n",
    "    predictions = [network_b[-1][pred][\"activation\"] for pred in range(len(network_b[-1]))]\n",
    "    targets = [tar for tar in target]\n",
    "    loss = cross_entropy_loss(predictions, targets)\n",
    "    print(f\"Cross Entropy Loss des Output layers: {loss}\")\n",
    "\n",
    "    for layer in reversed(range(len(network_b))): # man geht rckwÃ¤rts durch die liste aber die layerindexe bleiben die gleichen\n",
    "\n",
    "        print(f\"\\n ---------- Layer {layer} ---------- \\n\")\n",
    "    \n",
    "        # OUTPUT-LAYER und HIDDEN-LAYERS -----------------------\n",
    "        for neuron in range(len(network_b[layer])): # folgendes fÃ¼r jedes neurpn des letzen layer machen\n",
    "            \n",
    "            if layer == len(network_b)-1: # das letzte layer\n",
    "                a_target = target[neuron]\n",
    "                a_func = \"softmax\"\n",
    "                error = calc_error(network_b[-1][neuron][\"activation\"], a_target) # ERROR-BERECHNEN-FUNKTION\n",
    "            elif layer == 0: # das erste layer\n",
    "                a_func = \"relu\"\n",
    "                error = None\n",
    "                return network_b\n",
    "            else:\n",
    "                next_errors = [network_b[layer+1][err][\"error\"] for err in range(len(network_b[layer+1]))]\n",
    "                #print(f\"next_errors: {next_errors}\")\n",
    "                next_weights = [network_b[layer+1][w][\"weights\"][neuron] for w in range(len(network_b[layer+1]))]\n",
    "                a = network_b[layer][neuron][\"activation\"]\n",
    "                a_target = calc_target_a(next_errors, next_weights, a)\n",
    "                error = calc_error(network_b[layer][neuron][\"activation\"], a_target) # ERROR-BERECHNEN-FUNKTION\n",
    "\n",
    "            # den error ins dict hinzufÃ¼gen\n",
    "            network_b[layer][neuron][\"error\"] = error\n",
    "            print(f\"Error: {error}\")\n",
    "\n",
    "            # gradienten berechnen\n",
    "            weights = network_b[layer][neuron][\"weights\"]\n",
    "            prev_activations = [network_b[layer-1][n][\"activation\"] for n in range(len(network_b[layer-1]))]\n",
    "            bias = network_b[layer][neuron][\"bias\"]\n",
    "            a = network_b[layer][neuron][\"activation\"]\n",
    "        \n",
    "            gradients = calc_gradients(a_func, a, prev_activations, a_target) # GRADIENT-BERECHNEN-FUNKTION fÃ¼r die weigths\n",
    "            print(f\"Gradients of neuron Nr.{neuron}: {gradients}\")\n",
    "\n",
    "            # mithilfe der gradienten die neuen weights berechnen und mit den alten ersetzen\n",
    "            new_weights = [calc_new_weight(old_weight, lr, gradient) for old_weight, gradient in zip(weights, gradients)] # WEIGHT-UPDATE-FUNKTION\n",
    "            network_b[layer][neuron][\"weights\"] = new_weights\n",
    "            print(f\"Die weights: {weights} werden mit den weights {new_weights} ersetzt!\")\n",
    "\n",
    "            # die neuen biases berechnen und mit den alten ersetzen\n",
    "            new_bias = network_b[layer][neuron][\"bias\"] - lr * error\n",
    "            print(f\"der Bias: {bias} wird mit {new_bias} ersetzt!\")\n",
    "\n",
    "\n",
    "network_b = backprop(network_f, [0, 1], 0.01)\n",
    "\n",
    "print(f\"\\n------------------- Netzwerk (v.3) nach der Backward-Propagation mit verÃ¤nderten w, b -------------------\\n\")\n",
    "print_array_structure(network_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Das Model laufen lassen von A bis Z\n",
    "training: es wird immer ein loss berechnet, wie viel weicht die prediction vom gewollte wert ab? -> output der lossfunktion der backprop\n",
    "testing: was sagt die prediction? vertikal oder horizontal? -> output der softmax-funktion des outputlayers\n",
    "\n",
    "folgendes muss nich erledigt werden:\n",
    "- die weights irgendwo storen\n",
    "- daten irgedwo extern storen\n",
    "- frontend\n",
    "- abbildungen fÃ¼r das netz und die pixelbilder\n",
    "- statt von bild zu zahl (vertikal vs. horizontal) auch das umgekehert machen von zahl zu bild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== DATA ========\n",
      "Pixelbild: [0, 0, 0, 0, 0, 0, 1, 1, 1], Target: 1\n",
      "Netzwerk1: [[{'weights': None, 'bias': None, 'activation': None, 'error': None}, {'weights': None, 'bias': None, 'activation': None, 'error': None}, {'weights': None, 'bias': None, 'activation': None, 'error': None}, {'weights': None, 'bias': None, 'activation': None, 'error': None}, {'weights': None, 'bias': None, 'activation': None, 'error': None}, {'weights': None, 'bias': None, 'activation': None, 'error': None}, {'weights': None, 'bias': None, 'activation': None, 'error': None}, {'weights': None, 'bias': None, 'activation': None, 'error': None}, {'weights': None, 'bias': None, 'activation': None, 'error': None}], [{'weights': [-0.20575823848116392, 0.2201043214747186, -0.21695264882232124, 0.16565075557855768, 0.09788478079093976, -0.3936763251351326, -0.49508420608050885, -0.3665145696500822, 0.15000202079047686], 'bias': 0.35248515051710183, 'activation': None, 'error': None}, {'weights': [0.05524884492423865, -0.45869456404453557, 0.365216121884964, 0.09094517639455435, 0.21410396473886006, 0.02616875350609993, 0.08628237947481099, 0.1949082778283452, -0.2658908456268244], 'bias': 0.3617651395243815, 'activation': None, 'error': None}, {'weights': [0.16647946464775853, 0.31473075970805475, 0.4577689717150836, -0.08812716317423963, -0.25676616776267136, -0.14190008683929445, 0.4219094680204968, -0.16697687564848218, -0.00402878381359717], 'bias': -0.40101905211295064, 'activation': None, 'error': None}, {'weights': [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701], 'bias': -0.4498036763391735, 'activation': None, 'error': None}, {'weights': [-0.051873464806236225, 0.10464263794059225, -0.37735054204590013, 0.27568592802976144, -0.45666659825833944, -0.4581621809729136, 0.2399866001508142, 0.4184937033361027, 0.3294732612902822], 'bias': -0.3097403323387301, 'activation': None, 'error': None}], [{'weights': [0.2781435462194367, -0.4869195543356437, 0.432707693341323, 0.10930524983705137, 0.004321434274387692], 'bias': 0.42000886539078, 'activation': None, 'error': None}, {'weights': [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852], 'bias': -0.39195604157641695, 'activation': None, 'error': None}, {'weights': [0.4573580882298527, -0.2849251968314791, -0.15791731879017767, 0.08143634535064503, -0.47251616358203674], 'bias': 0.3567979477033839, 'activation': None, 'error': None}, {'weights': [0.005656180241009889, -0.05288807326375866, -0.15337363616658328, 0.26904289757018296, -0.010367959723265985], 'bias': 0.3834499349685605, 'activation': None, 'error': None}, {'weights': [-0.44608800966632345, -0.374971423655744, 0.43136805246346466, -0.463730136074775, -0.0267059718381083], 'bias': 0.2676336062123419, 'activation': None, 'error': None}], [{'weights': [0.3040350051877949, 0.362933057353379, 0.17230101454862534, -0.4152678717476682, -0.4217020525645335], 'bias': -0.15625408839192734, 'activation': None, 'error': None}, {'weights': [-0.4119681030297825, -0.05830109053717403, 0.36087237216399637, -0.2212145500596937, 0.21354452004835478], 'bias': -0.29033269689943275, 'activation': None, 'error': None}]]\n",
      "**Iteration 1**\n",
      "\n",
      "========== FP ============\n",
      "Prediction: horizontal\n",
      "Netzwerk2: [[{'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}], [{'weights': [-0.20575823848116392, 0.2201043214747186, -0.21695264882232124, 0.16565075557855768, 0.09788478079093976, -0.3936763251351326, -0.49508420608050885, -0.3665145696500822, 0.15000202079047686], 'bias': 0.35248515051710183, 'activation': 0, 'error': None}, {'weights': [0.05524884492423865, -0.45869456404453557, 0.365216121884964, 0.09094517639455435, 0.21410396473886006, 0.02616875350609993, 0.08628237947481099, 0.1949082778283452, -0.2658908456268244], 'bias': 0.3617651395243815, 'activation': 0.37706495120071326, 'error': None}, {'weights': [0.16647946464775853, 0.31473075970805475, 0.4577689717150836, -0.08812716317423963, -0.25676616776267136, -0.14190008683929445, 0.4219094680204968, -0.16697687564848218, -0.00402878381359717], 'bias': -0.40101905211295064, 'activation': 0, 'error': None}, {'weights': [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701], 'bias': -0.4498036763391735, 'activation': 0, 'error': None}, {'weights': [-0.051873464806236225, 0.10464263794059225, -0.37735054204590013, 0.27568592802976144, -0.45666659825833944, -0.4581621809729136, 0.2399866001508142, 0.4184937033361027, 0.3294732612902822], 'bias': -0.3097403323387301, 'activation': 0.678213232438469, 'error': None}], [{'weights': [0.2781435462194367, -0.4869195543356437, 0.432707693341323, 0.10930524983705137, 0.004321434274387692], 'bias': 0.42000886539078, 'activation': 0.2393394213045403, 'error': None}, {'weights': [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852], 'bias': -0.39195604157641695, 'activation': 0, 'error': None}, {'weights': [0.4573580882298527, -0.2849251968314791, -0.15791731879017767, 0.08143634535064503, -0.47251616358203674], 'bias': 0.3567979477033839, 'activation': 0, 'error': None}, {'weights': [0.005656180241009889, -0.05288807326375866, -0.15337363616658328, 0.26904289757018296, -0.010367959723265985], 'bias': 0.3834499349685605, 'activation': 0.3564760087265535, 'error': None}, {'weights': [-0.44608800966632345, -0.374971423655744, 0.43136805246346466, -0.463730136074775, -0.0267059718381083], 'bias': 0.2676336062123419, 'activation': 0.10813268116419267, 'error': None}], [{'weights': [0.3040350051877949, 0.362933057353379, 0.17230101454862534, -0.4152678717476682, -0.4217020525645335], 'bias': -0.15625408839192734, 'activation': 0.541797256745285, 'error': None}, {'weights': [-0.4119681030297825, -0.05830109053717403, 0.36087237216399637, -0.2212145500596937, 0.21354452004835478], 'bias': -0.29033269689943275, 'activation': 0.4582027432547151, 'error': None}]]\n",
      "\n",
      "========== BP ============\n",
      "Cross Entropy Loss des Output layers: 0.6128634125678715\n",
      "\n",
      " ---------- Layer 3 ---------- \n",
      "\n",
      "Error: 0.458202743254715\n",
      "Gradients of neuron Nr.0: [0.13450278859703504, 0.13450278859703504, 0.13450278859703504, 0.13450278859703504, 0.13450278859703504]\n",
      "Die weights: [0.3040350051877949, 0.362933057353379, 0.17230101454862534, -0.4152678717476682, -0.4217020525645335] werden mit den weights [0.30268997730182456, 0.36158802946740864, 0.170955986662655, -0.41661289963363857, -0.4230470804505039] ersetzt!\n",
      "der Bias: -0.15625408839192734 wird mit -0.1608361158244745 ersetzt!\n",
      "Error: -0.4582027432547151\n",
      "Gradients of neuron Nr.1: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [-0.4119681030297825, -0.05830109053717403, 0.36087237216399637, -0.2212145500596937, 0.21354452004835478] werden mit den weights [-0.4119681030297825, -0.05830109053717403, 0.36087237216399637, -0.2212145500596937, 0.21354452004835478] ersetzt!\n",
      "der Bias: -0.29033269689943275 wird mit -0.2857506694668856 ersetzt!\n",
      "\n",
      " ---------- Layer 2 ---------- \n",
      "\n",
      "Error: 0.08811887159255058\n",
      "Gradients of neuron Nr.0: [0.01426840329597653, 0.01426840329597653, 0.01426840329597653, 0.01426840329597653, 0.01426840329597653]\n",
      "Die weights: [0.2781435462194367, -0.4869195543356437, 0.432707693341323, 0.10930524983705137, 0.004321434274387692] werden mit den weights [0.27800086218647696, -0.48706223836860346, 0.4325650093083632, 0.1091625658040916, 0.0041787502414279264] ersetzt!\n",
      "der Bias: 0.42000886539078 wird mit 0.41912767667485445 ersetzt!\n",
      "Error: 0.0\n",
      "Gradients of neuron Nr.1: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852] werden mit den weights [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852] ersetzt!\n",
      "der Bias: -0.39195604157641695 wird mit -0.39195604157641695 ersetzt!\n",
      "Error: -0.0\n",
      "Gradients of neuron Nr.2: [-0.0, -0.0, -0.0, -0.0, -0.0]\n",
      "Die weights: [0.4573580882298527, -0.2849251968314791, -0.15791731879017767, 0.08143634535064503, -0.47251616358203674] werden mit den weights [0.4573580882298527, -0.2849251968314791, -0.15791731879017767, 0.08143634535064503, -0.47251616358203674] ersetzt!\n",
      "der Bias: 0.3567979477033839 wird mit 0.3567979477033839 ersetzt!\n",
      "Error: -0.4460080685287788\n",
      "Gradients of neuron Nr.3: [-0.007321565160598091, -0.007321565160598091, -0.007321565160598091, -0.007321565160598091, -0.007321565160598091]\n",
      "Die weights: [0.005656180241009889, -0.05288807326375866, -0.15337363616658328, 0.26904289757018296, -0.010367959723265985] werden mit den weights [0.00572939589261587, -0.05281485761215268, -0.1533004205149773, 0.26911611322178897, -0.010294744071660004] ersetzt!\n",
      "der Bias: 0.3834499349685605 wird mit 0.3879100156538483 ersetzt!\n",
      "Error: -0.39982069884567933\n",
      "Gradients of neuron Nr.4: [-0.003041814894815374, -0.003041814894815374, -0.003041814894815374, -0.003041814894815374, -0.003041814894815374]\n",
      "Die weights: [-0.44608800966632345, -0.374971423655744, 0.43136805246346466, -0.463730136074775, -0.0267059718381083] werden mit den weights [-0.4460575915173753, -0.3749410055067958, 0.4313984706124128, -0.4636997179258268, -0.026675553689160147] ersetzt!\n",
      "der Bias: 0.2676336062123419 wird mit 0.2716318132007987 ersetzt!\n",
      "\n",
      " ---------- Layer 1 ---------- \n",
      "\n",
      "Error: 0.0\n",
      "Gradients of neuron Nr.0: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [-0.20575823848116392, 0.2201043214747186, -0.21695264882232124, 0.16565075557855768, 0.09788478079093976, -0.3936763251351326, -0.49508420608050885, -0.3665145696500822, 0.15000202079047686] werden mit den weights [-0.20575823848116392, 0.2201043214747186, -0.21695264882232124, 0.16565075557855768, 0.09788478079093976, -0.3936763251351326, -0.49508420608050885, -0.3665145696500822, 0.15000202079047686] ersetzt!\n",
      "der Bias: 0.35248515051710183 wird mit 0.35248515051710183 ersetzt!\n",
      "Error: -0.246519298560249\n",
      "Gradients of neuron Nr.1: [0.011562121059144396, 0.011562121059144396, 0.011562121059144396, 0.011562121059144396, 0.011562121059144396, 0.011562121059144396, 0.011562121059144396, 0.011562121059144396, 0.011562121059144396]\n",
      "Die weights: [0.05524884492423865, -0.45869456404453557, 0.365216121884964, 0.09094517639455435, 0.21410396473886006, 0.02616875350609993, 0.08628237947481099, 0.1949082778283452, -0.2658908456268244] werden mit den weights [0.055133223713647206, -0.458810185255127, 0.36510050067437255, 0.0908295551839629, 0.21398834352826862, 0.026053132295508485, 0.08616675826421955, 0.19479265661775375, -0.26600646683741586] ersetzt!\n",
      "der Bias: 0.3617651395243815 wird mit 0.364230332509984 ersetzt!\n",
      "Error: -0.0\n",
      "Gradients of neuron Nr.2: [-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0]\n",
      "Die weights: [0.16647946464775853, 0.31473075970805475, 0.4577689717150836, -0.08812716317423963, -0.25676616776267136, -0.14190008683929445, 0.4219094680204968, -0.16697687564848218, -0.00402878381359717] werden mit den weights [0.16647946464775853, 0.31473075970805475, 0.4577689717150836, -0.08812716317423963, -0.25676616776267136, -0.14190008683929445, 0.4219094680204968, -0.16697687564848218, -0.00402878381359717] ersetzt!\n",
      "der Bias: -0.40101905211295064 wird mit -0.40101905211295064 ersetzt!\n",
      "Error: 0.0\n",
      "Gradients of neuron Nr.3: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701] werden mit den weights [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701] ersetzt!\n",
      "der Bias: -0.4498036763391735 wird mit -0.4498036763391735 ersetzt!\n",
      "Error: -0.6625880282450326\n",
      "Gradients of neuron Nr.4: [0.0023127378099374292, 0.0023127378099374292, 0.0023127378099374292, 0.0023127378099374292, 0.0023127378099374292, 0.0023127378099374292, 0.0023127378099374292, 0.0023127378099374292, 0.0023127378099374292]\n",
      "Die weights: [-0.051873464806236225, 0.10464263794059225, -0.37735054204590013, 0.27568592802976144, -0.45666659825833944, -0.4581621809729136, 0.2399866001508142, 0.4184937033361027, 0.3294732612902822] werden mit den weights [-0.0518965921843356, 0.10461951056249288, -0.3773736694239995, 0.27566280065166204, -0.45668972563643884, -0.458185308351013, 0.23996347277271482, 0.4184705759580033, 0.3294501339121828] ersetzt!\n",
      "der Bias: -0.3097403323387301 wird mit -0.3031144520562798 ersetzt!\n",
      "\n",
      " ---------- Layer 0 ---------- \n",
      "\n",
      "Netzwerk3: [[{'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}], [{'weights': [-0.20575823848116392, 0.2201043214747186, -0.21695264882232124, 0.16565075557855768, 0.09788478079093976, -0.3936763251351326, -0.49508420608050885, -0.3665145696500822, 0.15000202079047686], 'bias': 0.35248515051710183, 'activation': 0, 'error': 0.0}, {'weights': [0.055133223713647206, -0.458810185255127, 0.36510050067437255, 0.0908295551839629, 0.21398834352826862, 0.026053132295508485, 0.08616675826421955, 0.19479265661775375, -0.26600646683741586], 'bias': 0.3617651395243815, 'activation': 0.37706495120071326, 'error': -0.246519298560249}, {'weights': [0.16647946464775853, 0.31473075970805475, 0.4577689717150836, -0.08812716317423963, -0.25676616776267136, -0.14190008683929445, 0.4219094680204968, -0.16697687564848218, -0.00402878381359717], 'bias': -0.40101905211295064, 'activation': 0, 'error': -0.0}, {'weights': [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701], 'bias': -0.4498036763391735, 'activation': 0, 'error': 0.0}, {'weights': [-0.0518965921843356, 0.10461951056249288, -0.3773736694239995, 0.27566280065166204, -0.45668972563643884, -0.458185308351013, 0.23996347277271482, 0.4184705759580033, 0.3294501339121828], 'bias': -0.3097403323387301, 'activation': 0.678213232438469, 'error': -0.6625880282450326}], [{'weights': [0.27800086218647696, -0.48706223836860346, 0.4325650093083632, 0.1091625658040916, 0.0041787502414279264], 'bias': 0.42000886539078, 'activation': 0.2393394213045403, 'error': 0.08811887159255058}, {'weights': [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852], 'bias': -0.39195604157641695, 'activation': 0, 'error': 0.0}, {'weights': [0.4573580882298527, -0.2849251968314791, -0.15791731879017767, 0.08143634535064503, -0.47251616358203674], 'bias': 0.3567979477033839, 'activation': 0, 'error': -0.0}, {'weights': [0.00572939589261587, -0.05281485761215268, -0.1533004205149773, 0.26911611322178897, -0.010294744071660004], 'bias': 0.3834499349685605, 'activation': 0.3564760087265535, 'error': -0.4460080685287788}, {'weights': [-0.4460575915173753, -0.3749410055067958, 0.4313984706124128, -0.4636997179258268, -0.026675553689160147], 'bias': 0.2676336062123419, 'activation': 0.10813268116419267, 'error': -0.39982069884567933}], [{'weights': [0.30268997730182456, 0.36158802946740864, 0.170955986662655, -0.41661289963363857, -0.4230470804505039], 'bias': -0.15625408839192734, 'activation': 0.541797256745285, 'error': 0.458202743254715}, {'weights': [-0.4119681030297825, -0.05830109053717403, 0.36087237216399637, -0.2212145500596937, 0.21354452004835478], 'bias': -0.29033269689943275, 'activation': 0.4582027432547151, 'error': -0.4582027432547151}]]\n",
      "**Iteration 2**\n",
      "\n",
      "========== FP ============\n",
      "Prediction: horizontal\n",
      "Netzwerk2: [[{'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}], [{'weights': [-0.20575823848116392, 0.2201043214747186, -0.21695264882232124, 0.16565075557855768, 0.09788478079093976, -0.3936763251351326, -0.49508420608050885, -0.3665145696500822, 0.15000202079047686], 'bias': 0.35248515051710183, 'activation': 0.30395968313267796, 'error': 0.0}, {'weights': [0.055133223713647206, -0.458810185255127, 0.36510050067437255, 0.0908295551839629, 0.21398834352826862, 0.026053132295508485, 0.08616675826421955, 0.19479265661775375, -0.26600646683741586], 'bias': 0.3617651395243815, 'activation': 0.31173595441527685, 'error': -0.246519298560249}, {'weights': [0.16647946464775853, 0.31473075970805475, 0.4577689717150836, -0.08812716317423963, -0.25676616776267136, -0.14190008683929445, 0.4219094680204968, -0.16697687564848218, -0.00402878381359717], 'bias': -0.40101905211295064, 'activation': 0, 'error': -0.0}, {'weights': [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701], 'bias': -0.4498036763391735, 'activation': 0, 'error': 0.0}, {'weights': [-0.0518965921843356, 0.10461951056249288, -0.3773736694239995, 0.27566280065166204, -0.45668972563643884, -0.458185308351013, 0.23996347277271482, 0.4184705759580033, 0.3294501339121828], 'bias': -0.3097403323387301, 'activation': 0, 'error': -0.6625880282450326}], [{'weights': [0.27800086218647696, -0.48706223836860346, 0.4325650093083632, 0.1091625658040916, 0.0041787502414279264], 'bias': 0.42000886539078, 'activation': 0.35267510763411514, 'error': 0.08811887159255058}, {'weights': [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852], 'bias': -0.39195604157641695, 'activation': 0, 'error': 0.0}, {'weights': [0.4573580882298527, -0.2849251968314791, -0.15791731879017767, 0.08143634535064503, -0.47251616358203674], 'bias': 0.3567979477033839, 'activation': 0.40699493910867557, 'error': -0.0}, {'weights': [0.00572939589261587, -0.05281485761215268, -0.1533004205149773, 0.26911611322178897, -0.010294744071660004], 'bias': 0.3834499349685605, 'activation': 0.3687271502835903, 'error': -0.4460080685287788}, {'weights': [-0.4460575915173753, -0.3749410055067958, 0.4313984706124128, -0.4636997179258268, -0.026675553689160147], 'bias': 0.2676336062123419, 'activation': 0.01516748983471039, 'error': -0.39982069884567933}], [{'weights': [0.30268997730182456, 0.36158802946740864, 0.170955986662655, -0.41661289963363857, -0.4230470804505039], 'bias': -0.15625408839192734, 'activation': 0.5565375573880321, 'error': 0.458202743254715}, {'weights': [-0.4119681030297825, -0.05830109053717403, 0.36087237216399637, -0.2212145500596937, 0.21354452004835478], 'bias': -0.29033269689943275, 'activation': 0.4434624426119679, 'error': -0.4582027432547151}]]\n",
      "\n",
      "========== BP ============\n",
      "Cross Entropy Loss des Output layers: 0.8131421648951371\n",
      "\n",
      " ---------- Layer 3 ---------- \n",
      "\n",
      "Error: -0.5565375573880321\n",
      "Gradients of neuron Nr.0: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [0.30268997730182456, 0.36158802946740864, 0.170955986662655, -0.41661289963363857, -0.4230470804505039] werden mit den weights [0.30268997730182456, 0.36158802946740864, 0.170955986662655, -0.41661289963363857, -0.4230470804505039] ersetzt!\n",
      "der Bias: -0.15625408839192734 wird mit -0.15068871281804702 ersetzt!\n",
      "Error: 0.5565375573880321\n",
      "Gradients of neuron Nr.1: [0.10944808499714774, 0.10944808499714774, 0.10944808499714774, 0.10944808499714774, 0.10944808499714774]\n",
      "Die weights: [-0.4119681030297825, -0.05830109053717403, 0.36087237216399637, -0.2212145500596937, 0.21354452004835478] werden mit den weights [-0.413062583879754, -0.059395571387145504, 0.3597778913140249, -0.2223090309096652, 0.2124500391983833] ersetzt!\n",
      "der Bias: -0.29033269689943275 wird mit -0.29589807247331307 ersetzt!\n",
      "\n",
      " ---------- Layer 2 ---------- \n",
      "\n",
      "Error: -0.7510182897283388\n",
      "Gradients of neuron Nr.0: [-0.0320722413374025, -0.0320722413374025, -0.0320722413374025, -0.0320722413374025, -0.0320722413374025]\n",
      "Die weights: [0.27800086218647696, -0.48706223836860346, 0.4325650093083632, 0.1091625658040916, 0.0041787502414279264] werden mit den weights [0.278321584599851, -0.4867415159552294, 0.4328857317217373, 0.10948328821746563, 0.004499472654801951] ersetzt!\n",
      "der Bias: 0.42000886539078 wird mit 0.42751904828806336 ersetzt!\n",
      "Error: -0.0\n",
      "Gradients of neuron Nr.1: [-0.0, -0.0, -0.0, -0.0, -0.0]\n",
      "Die weights: [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852] werden mit den weights [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852] ersetzt!\n",
      "der Bias: -0.39195604157641695 wird mit -0.39195604157641695 ersetzt!\n",
      "Error: -0.3019084575126463\n",
      "Gradients of neuron Nr.2: [0.010322461440518838, 0.010322461440518838, 0.010322461440518838, 0.010322461440518838, 0.010322461440518838]\n",
      "Die weights: [0.4573580882298527, -0.2849251968314791, -0.15791731879017767, 0.08143634535064503, -0.47251616358203674] werden mit den weights [0.4572548636154475, -0.2850284214458843, -0.15802054340458285, 0.08133312073623984, -0.47261938819644195] ersetzt!\n",
      "der Bias: 0.3567979477033839 wird mit 0.35981703227851036 ersetzt!\n",
      "Error: -0.26058974979290533\n",
      "Gradients of neuron Nr.3: [0.009281181603506043, 0.009281181603506043, 0.009281181603506043, 0.009281181603506043, 0.009281181603506043]\n",
      "Die weights: [0.00572939589261587, -0.05281485761215268, -0.1533004205149773, 0.26911611322178897, -0.010294744071660004] werden mit den weights [0.0056365840765808094, -0.05290766942818774, -0.15339323233101237, 0.2690233014057539, -0.010387555887695065] ersetzt!\n",
      "der Bias: 0.3834499349685605 wird mit 0.38605583246648956 ersetzt!\n",
      "Error: 0.33851052486181127\n",
      "Gradients of neuron Nr.4: [8.013050241733535e-05, 8.013050241733535e-05, 8.013050241733535e-05, 8.013050241733535e-05, 8.013050241733535e-05]\n",
      "Die weights: [-0.4460575915173753, -0.3749410055067958, 0.4313984706124128, -0.4636997179258268, -0.026675553689160147] werden mit den weights [-0.44605839282239945, -0.37494180681182, 0.43139766930738865, -0.463700519230851, -0.02667635499418432] ersetzt!\n",
      "der Bias: 0.2676336062123419 wird mit 0.26424850096372376 ersetzt!\n",
      "\n",
      " ---------- Layer 1 ---------- \n",
      "\n",
      "Error: -0.8034976908651636\n",
      "Gradients of neuron Nr.0: [-0.03212439073758308, -0.03212439073758308, -0.03212439073758308, -0.03212439073758308, -0.03212439073758308, -0.03212439073758308, -0.03212439073758308, -0.03212439073758308, -0.03212439073758308]\n",
      "Die weights: [-0.20575823848116392, 0.2201043214747186, -0.21695264882232124, 0.16565075557855768, 0.09788478079093976, -0.3936763251351326, -0.49508420608050885, -0.3665145696500822, 0.15000202079047686] werden mit den weights [-0.20543699457378808, 0.22042556538209443, -0.2166314049149454, 0.16597199948593352, 0.09820602469831559, -0.3933550812277568, -0.49476296217313304, -0.3661933257427064, 0.1503232646978527] ersetzt!\n",
      "der Bias: 0.35248515051710183 wird mit 0.36052012742575346 ersetzt!\n",
      "Error: 0.02673376602510208\n",
      "Gradients of neuron Nr.1: [0.022638554628881345, 0.022638554628881345, 0.022638554628881345, 0.022638554628881345, 0.022638554628881345, 0.022638554628881345, 0.022638554628881345, 0.022638554628881345, 0.022638554628881345]\n",
      "Die weights: [0.055133223713647206, -0.458810185255127, 0.36510050067437255, 0.0908295551839629, 0.21398834352826862, 0.026053132295508485, 0.08616675826421955, 0.19479265661775375, -0.26600646683741586] werden mit den weights [0.05490683816735839, -0.4590365708014158, 0.36487411512808376, 0.09060316963767409, 0.2137619579819798, 0.025826746749219674, 0.08594037271793073, 0.19456627107146493, -0.26623285238370464] ersetzt!\n",
      "der Bias: 0.3617651395243815 wird mit 0.3614978018641305 ersetzt!\n",
      "Error: -0.0\n",
      "Gradients of neuron Nr.2: [-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0]\n",
      "Die weights: [0.16647946464775853, 0.31473075970805475, 0.4577689717150836, -0.08812716317423963, -0.25676616776267136, -0.14190008683929445, 0.4219094680204968, -0.16697687564848218, -0.00402878381359717] werden mit den weights [0.16647946464775853, 0.31473075970805475, 0.4577689717150836, -0.08812716317423963, -0.25676616776267136, -0.14190008683929445, 0.4219094680204968, -0.16697687564848218, -0.00402878381359717] ersetzt!\n",
      "der Bias: -0.40101905211295064 wird mit -0.40101905211295064 ersetzt!\n",
      "Error: -0.0\n",
      "Gradients of neuron Nr.3: [-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0]\n",
      "Die weights: [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701] werden mit den weights [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701] ersetzt!\n",
      "der Bias: -0.4498036763391735 wird mit -0.4498036763391735 ersetzt!\n",
      "Error: 0.0\n",
      "Gradients of neuron Nr.4: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [-0.0518965921843356, 0.10461951056249288, -0.3773736694239995, 0.27566280065166204, -0.45668972563643884, -0.458185308351013, 0.23996347277271482, 0.4184705759580033, 0.3294501339121828] werden mit den weights [-0.0518965921843356, 0.10461951056249288, -0.3773736694239995, 0.27566280065166204, -0.45668972563643884, -0.458185308351013, 0.23996347277271482, 0.4184705759580033, 0.3294501339121828] ersetzt!\n",
      "der Bias: -0.3097403323387301 wird mit -0.3097403323387301 ersetzt!\n",
      "\n",
      " ---------- Layer 0 ---------- \n",
      "\n",
      "Netzwerk3: [[{'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}], [{'weights': [-0.20543699457378808, 0.22042556538209443, -0.2166314049149454, 0.16597199948593352, 0.09820602469831559, -0.3933550812277568, -0.49476296217313304, -0.3661933257427064, 0.1503232646978527], 'bias': 0.35248515051710183, 'activation': 0.30395968313267796, 'error': -0.8034976908651636}, {'weights': [0.05490683816735839, -0.4590365708014158, 0.36487411512808376, 0.09060316963767409, 0.2137619579819798, 0.025826746749219674, 0.08594037271793073, 0.19456627107146493, -0.26623285238370464], 'bias': 0.3617651395243815, 'activation': 0.31173595441527685, 'error': 0.02673376602510208}, {'weights': [0.16647946464775853, 0.31473075970805475, 0.4577689717150836, -0.08812716317423963, -0.25676616776267136, -0.14190008683929445, 0.4219094680204968, -0.16697687564848218, -0.00402878381359717], 'bias': -0.40101905211295064, 'activation': 0, 'error': -0.0}, {'weights': [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701], 'bias': -0.4498036763391735, 'activation': 0, 'error': -0.0}, {'weights': [-0.0518965921843356, 0.10461951056249288, -0.3773736694239995, 0.27566280065166204, -0.45668972563643884, -0.458185308351013, 0.23996347277271482, 0.4184705759580033, 0.3294501339121828], 'bias': -0.3097403323387301, 'activation': 0, 'error': 0.0}], [{'weights': [0.278321584599851, -0.4867415159552294, 0.4328857317217373, 0.10948328821746563, 0.004499472654801951], 'bias': 0.42000886539078, 'activation': 0.35267510763411514, 'error': -0.7510182897283388}, {'weights': [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852], 'bias': -0.39195604157641695, 'activation': 0, 'error': -0.0}, {'weights': [0.4572548636154475, -0.2850284214458843, -0.15802054340458285, 0.08133312073623984, -0.47261938819644195], 'bias': 0.3567979477033839, 'activation': 0.40699493910867557, 'error': -0.3019084575126463}, {'weights': [0.0056365840765808094, -0.05290766942818774, -0.15339323233101237, 0.2690233014057539, -0.010387555887695065], 'bias': 0.3834499349685605, 'activation': 0.3687271502835903, 'error': -0.26058974979290533}, {'weights': [-0.44605839282239945, -0.37494180681182, 0.43139766930738865, -0.463700519230851, -0.02667635499418432], 'bias': 0.2676336062123419, 'activation': 0.01516748983471039, 'error': 0.33851052486181127}], [{'weights': [0.30268997730182456, 0.36158802946740864, 0.170955986662655, -0.41661289963363857, -0.4230470804505039], 'bias': -0.15625408839192734, 'activation': 0.5565375573880321, 'error': -0.5565375573880321}, {'weights': [-0.413062583879754, -0.059395571387145504, 0.3597778913140249, -0.2223090309096652, 0.2124500391983833], 'bias': -0.29033269689943275, 'activation': 0.4434624426119679, 'error': 0.5565375573880321}]]\n",
      "**Iteration 3**\n",
      "\n",
      "========== FP ============\n",
      "Prediction: horizontal\n",
      "Netzwerk2: [[{'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}], [{'weights': [-0.20543699457378808, 0.22042556538209443, -0.2166314049149454, 0.16597199948593352, 0.09820602469831559, -0.3933550812277568, -0.49476296217313304, -0.3661933257427064, 0.1503232646978527], 'bias': 0.35248515051710183, 'activation': 0.15084231641046278, 'error': -0.8034976908651636}, {'weights': [0.05490683816735839, -0.4590365708014158, 0.36487411512808376, 0.09060316963767409, 0.2137619579819798, 0.025826746749219674, 0.08594037271793073, 0.19456627107146493, -0.26623285238370464], 'bias': 0.3617651395243815, 'activation': 0.3225095220184079, 'error': 0.02673376602510208}, {'weights': [0.16647946464775853, 0.31473075970805475, 0.4577689717150836, -0.08812716317423963, -0.25676616776267136, -0.14190008683929445, 0.4219094680204968, -0.16697687564848218, -0.00402878381359717], 'bias': -0.40101905211295064, 'activation': 0.5379601439579462, 'error': -0.0}, {'weights': [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701], 'bias': -0.4498036763391735, 'activation': 0, 'error': -0.0}, {'weights': [-0.0518965921843356, 0.10461951056249288, -0.3773736694239995, 0.27566280065166204, -0.45668972563643884, -0.458185308351013, 0.23996347277271482, 0.4184705759580033, 0.3294501339121828], 'bias': -0.3097403323387301, 'activation': 0, 'error': 0.0}], [{'weights': [0.278321584599851, -0.4867415159552294, 0.4328857317217373, 0.10948328821746563, 0.004499472654801951], 'bias': 0.42000886539078, 'activation': 0.5378880348159825, 'error': -0.7510182897283388}, {'weights': [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852], 'bias': -0.39195604157641695, 'activation': 0, 'error': -0.0}, {'weights': [0.4572548636154475, -0.2850284214458843, -0.15802054340458285, 0.08133312073623984, -0.47261938819644195], 'bias': 0.3567979477033839, 'activation': 0.2488381962806725, 'error': -0.3019084575126463}, {'weights': [0.0056365840765808094, -0.05290766942818774, -0.15339323233101237, 0.2690233014057539, -0.010387555887695065], 'bias': 0.3834499349685605, 'activation': 0.28471749784195544, 'error': -0.26058974979290533}, {'weights': [-0.44605839282239945, -0.37494180681182, 0.43139766930738865, -0.463700519230851, -0.02667635499418432], 'bias': 0.2676336062123419, 'activation': 0.31150157436881, 'error': 0.33851052486181127}], [{'weights': [0.30268997730182456, 0.36158802946740864, 0.170955986662655, -0.41661289963363857, -0.4230470804505039], 'bias': -0.15625408839192734, 'activation': 0.5544845903313924, 'error': -0.5565375573880321}, {'weights': [-0.413062583879754, -0.059395571387145504, 0.3597778913140249, -0.2223090309096652, 0.2124500391983833], 'bias': -0.29033269689943275, 'activation': 0.44551540966860753, 'error': 0.5565375573880321}]]\n",
      "\n",
      "========== BP ============\n",
      "Cross Entropy Loss des Output layers: 0.5897162627827531\n",
      "\n",
      " ---------- Layer 3 ---------- \n",
      "\n",
      "Error: 0.4455154096686076\n",
      "Gradients of neuron Nr.0: [0.13697512093894212, 0.13697512093894212, 0.13697512093894212, 0.13697512093894212, 0.13697512093894212]\n",
      "Die weights: [0.30268997730182456, 0.36158802946740864, 0.170955986662655, -0.41661289963363857, -0.4230470804505039] werden mit den weights [0.30132022609243514, 0.3602182782580192, 0.16958623545326557, -0.417982650843028, -0.4244168316598933] ersetzt!\n",
      "der Bias: -0.15625408839192734 wird mit -0.1607092424886134 ersetzt!\n",
      "Error: -0.44551540966860753\n",
      "Gradients of neuron Nr.1: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [-0.413062583879754, -0.059395571387145504, 0.3597778913140249, -0.2223090309096652, 0.2124500391983833] werden mit den weights [-0.413062583879754, -0.059395571387145504, 0.3597778913140249, -0.2223090309096652, 0.2124500391983833] ersetzt!\n",
      "der Bias: -0.29033269689943275 wird mit -0.2858775428027467 ersetzt!\n",
      "\n",
      " ---------- Layer 2 ---------- \n",
      "\n",
      "Error: -0.2196194845710116\n",
      "Gradients of neuron Nr.0: [0.04255246338492925, 0.04255246338492925, 0.04255246338492925, 0.04255246338492925, 0.04255246338492925]\n",
      "Die weights: [0.278321584599851, -0.4867415159552294, 0.4328857317217373, 0.10948328821746563, 0.004499472654801951] werden mit den weights [0.2778960599660017, -0.4871670405890787, 0.43246020708788796, 0.10905776358361634, 0.004073948020952659] ersetzt!\n",
      "der Bias: 0.42000886539078 wird mit 0.42220506023649007 ersetzt!\n",
      "Error: 0.0\n",
      "Gradients of neuron Nr.1: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852] werden mit den weights [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852] ersetzt!\n",
      "der Bias: -0.39195604157641695 wird mit -0.39195604157641695 ersetzt!\n",
      "Error: -0.3335715097570295\n",
      "Gradients of neuron Nr.2: [-0.003941139207973308, -0.003941139207973308, -0.003941139207973308, -0.003941139207973308, -0.003941139207973308]\n",
      "Die weights: [0.4572548636154475, -0.2850284214458843, -0.15802054340458285, 0.08133312073623984, -0.47261938819644195] werden mit den weights [0.45729427500752723, -0.28498901005380456, -0.1579811320125031, 0.08137253212831957, -0.4725799768043622] ersetzt!\n",
      "der Bias: 0.3567979477033839 wird mit 0.3601336628009542 ersetzt!\n",
      "Error: -0.371893110787907\n",
      "Gradients of neuron Nr.3: [-0.00505476450798997, -0.00505476450798997, -0.00505476450798997, -0.00505476450798997, -0.00505476450798997]\n",
      "Die weights: [0.0056365840765808094, -0.05290766942818774, -0.15339323233101237, 0.2690233014057539, -0.010387555887695065] werden mit den weights [0.005687131721660709, -0.05285712178310784, -0.15334268468593248, 0.2690738490508338, -0.010337008242615166] ersetzt!\n",
      "der Bias: 0.3834499349685605 wird mit 0.3871688660764396 ersetzt!\n",
      "Error: -0.5952355792435993\n",
      "Gradients of neuron Nr.4: [-0.01895548197575225, -0.01895548197575225, -0.01895548197575225, -0.01895548197575225, -0.01895548197575225]\n",
      "Die weights: [-0.44605839282239945, -0.37494180681182, 0.43139766930738865, -0.463700519230851, -0.02667635499418432] werden mit den weights [-0.44586883800264193, -0.37475225199206247, 0.4315872241271462, -0.46351096441109346, -0.026486800174426797] ersetzt!\n",
      "der Bias: 0.2676336062123419 wird mit 0.27358596200477786 ersetzt!\n",
      "\n",
      " ---------- Layer 1 ---------- \n",
      "\n",
      "Error: -0.10113205663427402\n",
      "Gradients of neuron Nr.0: [0.000960463272575901, 0.000960463272575901, 0.000960463272575901, 0.000960463272575901, 0.000960463272575901, 0.000960463272575901, 0.000960463272575901, 0.000960463272575901, 0.000960463272575901]\n",
      "Die weights: [-0.20543699457378808, 0.22042556538209443, -0.2166314049149454, 0.16597199948593352, 0.09820602469831559, -0.3933550812277568, -0.49476296217313304, -0.3661933257427064, 0.1503232646978527] werden mit den weights [-0.20544659920651384, 0.22041596074936867, -0.21664100954767115, 0.16596239485320777, 0.09819642006558983, -0.39336468586048257, -0.4947725668058588, -0.36620293037543217, 0.15031366006512695] ersetzt!\n",
      "der Bias: 0.35248515051710183 wird mit 0.35349647108344456 ersetzt!\n",
      "Error: 0.12226913991811333\n",
      "Gradients of neuron Nr.1: [0.03134239812006629, 0.03134239812006629, 0.03134239812006629, 0.03134239812006629, 0.03134239812006629, 0.03134239812006629, 0.03134239812006629, 0.03134239812006629, 0.03134239812006629]\n",
      "Die weights: [0.05490683816735839, -0.4590365708014158, 0.36487411512808376, 0.09060316963767409, 0.2137619579819798, 0.025826746749219674, 0.08594037271793073, 0.19456627107146493, -0.26623285238370464] werden mit den weights [0.05459341418615773, -0.45934999478261646, 0.3645606911468831, 0.09028974565647342, 0.21344853400077915, 0.02551332276801901, 0.08562694873673006, 0.19425284709026427, -0.2665462763649053] ersetzt!\n",
      "der Bias: 0.3617651395243815 wird mit 0.36054244812520037 ersetzt!\n",
      "Error: -0.7801078103405643\n",
      "Gradients of neuron Nr.2: [-0.032378738936675075, -0.032378738936675075, -0.032378738936675075, -0.032378738936675075, -0.032378738936675075, -0.032378738936675075, -0.032378738936675075, -0.032378738936675075, -0.032378738936675075]\n",
      "Die weights: [0.16647946464775853, 0.31473075970805475, 0.4577689717150836, -0.08812716317423963, -0.25676616776267136, -0.14190008683929445, 0.4219094680204968, -0.16697687564848218, -0.00402878381359717] werden mit den weights [0.1668032520371253, 0.3150545470974215, 0.4580927591044503, -0.08780337578487288, -0.25644238037330463, -0.1415762994499277, 0.4222332554098635, -0.16665308825911543, -0.003704996424230419] ersetzt!\n",
      "der Bias: -0.40101905211295064 wird mit -0.393217974009545 ersetzt!\n",
      "Error: 0.0\n",
      "Gradients of neuron Nr.3: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701] werden mit den weights [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701] ersetzt!\n",
      "der Bias: -0.4498036763391735 wird mit -0.4498036763391735 ersetzt!\n",
      "Error: 0.0\n",
      "Gradients of neuron Nr.4: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [-0.0518965921843356, 0.10461951056249288, -0.3773736694239995, 0.27566280065166204, -0.45668972563643884, -0.458185308351013, 0.23996347277271482, 0.4184705759580033, 0.3294501339121828] werden mit den weights [-0.0518965921843356, 0.10461951056249288, -0.3773736694239995, 0.27566280065166204, -0.45668972563643884, -0.458185308351013, 0.23996347277271482, 0.4184705759580033, 0.3294501339121828] ersetzt!\n",
      "der Bias: -0.3097403323387301 wird mit -0.3097403323387301 ersetzt!\n",
      "\n",
      " ---------- Layer 0 ---------- \n",
      "\n",
      "Netzwerk3: [[{'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}], [{'weights': [-0.20544659920651384, 0.22041596074936867, -0.21664100954767115, 0.16596239485320777, 0.09819642006558983, -0.39336468586048257, -0.4947725668058588, -0.36620293037543217, 0.15031366006512695], 'bias': 0.35248515051710183, 'activation': 0.15084231641046278, 'error': -0.10113205663427402}, {'weights': [0.05459341418615773, -0.45934999478261646, 0.3645606911468831, 0.09028974565647342, 0.21344853400077915, 0.02551332276801901, 0.08562694873673006, 0.19425284709026427, -0.2665462763649053], 'bias': 0.3617651395243815, 'activation': 0.3225095220184079, 'error': 0.12226913991811333}, {'weights': [0.1668032520371253, 0.3150545470974215, 0.4580927591044503, -0.08780337578487288, -0.25644238037330463, -0.1415762994499277, 0.4222332554098635, -0.16665308825911543, -0.003704996424230419], 'bias': -0.40101905211295064, 'activation': 0.5379601439579462, 'error': -0.7801078103405643}, {'weights': [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701], 'bias': -0.4498036763391735, 'activation': 0, 'error': 0.0}, {'weights': [-0.0518965921843356, 0.10461951056249288, -0.3773736694239995, 0.27566280065166204, -0.45668972563643884, -0.458185308351013, 0.23996347277271482, 0.4184705759580033, 0.3294501339121828], 'bias': -0.3097403323387301, 'activation': 0, 'error': 0.0}], [{'weights': [0.2778960599660017, -0.4871670405890787, 0.43246020708788796, 0.10905776358361634, 0.004073948020952659], 'bias': 0.42000886539078, 'activation': 0.5378880348159825, 'error': -0.2196194845710116}, {'weights': [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852], 'bias': -0.39195604157641695, 'activation': 0, 'error': 0.0}, {'weights': [0.45729427500752723, -0.28498901005380456, -0.1579811320125031, 0.08137253212831957, -0.4725799768043622], 'bias': 0.3567979477033839, 'activation': 0.2488381962806725, 'error': -0.3335715097570295}, {'weights': [0.005687131721660709, -0.05285712178310784, -0.15334268468593248, 0.2690738490508338, -0.010337008242615166], 'bias': 0.3834499349685605, 'activation': 0.28471749784195544, 'error': -0.371893110787907}, {'weights': [-0.44586883800264193, -0.37475225199206247, 0.4315872241271462, -0.46351096441109346, -0.026486800174426797], 'bias': 0.2676336062123419, 'activation': 0.31150157436881, 'error': -0.5952355792435993}], [{'weights': [0.30132022609243514, 0.3602182782580192, 0.16958623545326557, -0.417982650843028, -0.4244168316598933], 'bias': -0.15625408839192734, 'activation': 0.5544845903313924, 'error': 0.4455154096686076}, {'weights': [-0.413062583879754, -0.059395571387145504, 0.3597778913140249, -0.2223090309096652, 0.2124500391983833], 'bias': -0.29033269689943275, 'activation': 0.44551540966860753, 'error': -0.44551540966860753}]]\n",
      "**Iteration 4**\n",
      "\n",
      "========== FP ============\n",
      "Prediction: horizontal\n",
      "Netzwerk2: [[{'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}], [{'weights': [-0.20544659920651384, 0.22041596074936867, -0.21664100954767115, 0.16596239485320777, 0.09819642006558983, -0.39336468586048257, -0.4947725668058588, -0.36620293037543217, 0.15031366006512695], 'bias': 0.35248515051710183, 'activation': 0, 'error': -0.10113205663427402}, {'weights': [0.05459341418615773, -0.45934999478261646, 0.3645606911468831, 0.09028974565647342, 0.21344853400077915, 0.02551332276801901, 0.08562694873673006, 0.19425284709026427, -0.2665462763649053], 'bias': 0.3617651395243815, 'activation': 0.5922752481037428, 'error': 0.12226913991811333}, {'weights': [0.1668032520371253, 0.3150545470974215, 0.4580927591044503, -0.08780337578487288, -0.25644238037330463, -0.1415762994499277, 0.4222332554098635, -0.16665308825911543, -0.003704996424230419], 'bias': -0.40101905211295064, 'activation': 0.10021407954916528, 'error': -0.7801078103405643}, {'weights': [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701], 'bias': -0.4498036763391735, 'activation': 0, 'error': 0.0}, {'weights': [-0.0518965921843356, 0.10461951056249288, -0.3773736694239995, 0.27566280065166204, -0.45668972563643884, -0.458185308351013, 0.23996347277271482, 0.4184705759580033, 0.3294501339121828], 'bias': -0.3097403323387301, 'activation': 0.15398934890131116, 'error': 0.0}], [{'weights': [0.2778960599660017, -0.4871670405890787, 0.43246020708788796, 0.10905776358361634, 0.004073948020952659], 'bias': 0.42000886539078, 'activation': 0.1754378317560756, 'error': -0.2196194845710116}, {'weights': [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852], 'bias': -0.39195604157641695, 'activation': 0, 'error': 0.0}, {'weights': [0.45729427500752723, -0.28498901005380456, -0.1579811320125031, 0.08137253212831957, -0.4725799768043622], 'bias': 0.3567979477033839, 'activation': 0.09940179440425811, 'error': -0.3335715097570295}, {'weights': [0.005687131721660709, -0.05285712178310784, -0.15334268468593248, 0.2690738490508338, -0.010337008242615166], 'bias': 0.3834499349685605, 'activation': 0.33518508488015414, 'error': -0.371893110787907}, {'weights': [-0.44586883800264193, -0.37475225199206247, 0.4315872241271462, -0.46351096441109346, -0.026486800174426797], 'bias': 0.2676336062123419, 'activation': 0.0848495544840489, 'error': -0.5952355792435993}], [{'weights': [0.30132022609243514, 0.3602182782580192, 0.16958623545326557, -0.417982650843028, -0.4244168316598933], 'bias': -0.15625408839192734, 'activation': 0.5301828171457316, 'error': 0.4455154096686076}, {'weights': [-0.413062583879754, -0.059395571387145504, 0.3597778913140249, -0.2223090309096652, 0.2124500391983833], 'bias': -0.29033269689943275, 'activation': 0.4698171828542684, 'error': -0.44551540966860753}]]\n",
      "\n",
      "========== BP ============\n",
      "Cross Entropy Loss des Output layers: 0.7554116325980099\n",
      "\n",
      " ---------- Layer 3 ---------- \n",
      "\n",
      "Error: -0.5301828171457316\n",
      "Gradients of neuron Nr.0: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [0.30132022609243514, 0.3602182782580192, 0.16958623545326557, -0.417982650843028, -0.4244168316598933] werden mit den weights [0.30132022609243514, 0.3602182782580192, 0.16958623545326557, -0.417982650843028, -0.4244168316598933] ersetzt!\n",
      "der Bias: -0.15625408839192734 wird mit -0.15095226022047 ersetzt!\n",
      "Error: 0.5301828171457317\n",
      "Gradients of neuron Nr.1: [0.11702629110853417, 0.11702629110853417, 0.11702629110853417, 0.11702629110853417, 0.11702629110853417]\n",
      "Die weights: [-0.413062583879754, -0.059395571387145504, 0.3597778913140249, -0.2223090309096652, 0.2124500391983833] werden mit den weights [-0.4142328467908393, -0.06056583429823085, 0.3586076284029395, -0.22347929382075055, 0.21127977628729794] ersetzt!\n",
      "der Bias: -0.29033269689943275 wird mit -0.29563452507089005 ersetzt!\n",
      "\n",
      " ---------- Layer 2 ---------- \n",
      "\n",
      "Error: -0.554811775754615\n",
      "Gradients of neuron Nr.0: [-0.009628029384688977, -0.009628029384688977, -0.009628029384688977, -0.009628029384688977, -0.009628029384688977]\n",
      "Die weights: [0.2778960599660017, -0.4871670405890787, 0.43246020708788796, 0.10905776358361634, 0.004073948020952659] werden mit den weights [0.2779923402598486, -0.48707076029523183, 0.43255648738173486, 0.10915404387746323, 0.004170228314799549] ersetzt!\n",
      "der Bias: 0.42000886539078 wird mit 0.42555698314832613 ersetzt!\n",
      "Error: -0.0\n",
      "Gradients of neuron Nr.1: [-0.0, -0.0, -0.0, -0.0, -0.0]\n",
      "Die weights: [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852] werden mit den weights [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852] ersetzt!\n",
      "der Bias: -0.39195604157641695 wird mit -0.39195604157641695 ersetzt!\n",
      "Error: 0.0008141002106103884\n",
      "Gradients of neuron Nr.2: [0.0008917767260428101, 0.0008917767260428101, 0.0008917767260428101, 0.0008917767260428101, 0.0008917767260428101]\n",
      "Die weights: [0.45729427500752723, -0.28498901005380456, -0.1579811320125031, 0.08137253212831957, -0.4725799768043622] werden mit den weights [0.4572853572402668, -0.284997927821065, -0.15799004977976353, 0.08136361436105914, -0.4725888945716226] ersetzt!\n",
      "der Bias: 0.3567979477033839 wird mit 0.3567898067012778 ersetzt!\n",
      "Error: -0.2320627471097811\n",
      "Gradients of neuron Nr.3: [0.007702343348065374, 0.007702343348065374, 0.007702343348065374, 0.007702343348065374, 0.007702343348065374]\n",
      "Die weights: [0.005687131721660709, -0.05285712178310784, -0.15334268468593248, 0.2690738490508338, -0.010337008242615166] werden mit den weights [0.005610108288180055, -0.0529341452165885, -0.15341970811941313, 0.26899682561735316, -0.010414031676095819] ersetzt!\n",
      "der Bias: 0.3834499349685605 wird mit 0.3857705624396583 ersetzt!\n",
      "Error: 0.25218586396737863\n",
      "Gradients of neuron Nr.4: [0.0022205838178128716, 0.0022205838178128716, 0.0022205838178128716, 0.0022205838178128716, 0.0022205838178128716]\n",
      "Die weights: [-0.44586883800264193, -0.37475225199206247, 0.4315872241271462, -0.46351096441109346, -0.026486800174426797] werden mit den weights [-0.44589104384082007, -0.3747744578302406, 0.43156501828896804, -0.4635331702492716, -0.026509006012604926] ersetzt!\n",
      "der Bias: 0.2676336062123419 wird mit 0.2651117475726681 ersetzt!\n",
      "\n",
      " ---------- Layer 1 ---------- \n",
      "\n",
      "Error: -0.0\n",
      "Gradients of neuron Nr.0: [-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0]\n",
      "Die weights: [-0.20544659920651384, 0.22041596074936867, -0.21664100954767115, 0.16596239485320777, 0.09819642006558983, -0.39336468586048257, -0.4947725668058588, -0.36620293037543217, 0.15031366006512695] werden mit den weights [-0.20544659920651384, 0.22041596074936867, -0.21664100954767115, 0.16596239485320777, 0.09819642006558983, -0.39336468586048257, -0.4947725668058588, -0.36620293037543217, 0.15031366006512695] ersetzt!\n",
      "der Bias: 0.35248515051710183 wird mit 0.35248515051710183 ersetzt!\n",
      "Error: -0.40450344882521294\n",
      "Gradients of neuron Nr.1: [0.02685620303819559, 0.02685620303819559, 0.02685620303819559, 0.02685620303819559, 0.02685620303819559, 0.02685620303819559, 0.02685620303819559, 0.02685620303819559, 0.02685620303819559]\n",
      "Die weights: [0.05459341418615773, -0.45934999478261646, 0.3645606911468831, 0.09028974565647342, 0.21344853400077915, 0.02551332276801901, 0.08562694873673006, 0.19425284709026427, -0.2665462763649053] werden mit den weights [0.054324852155775774, -0.4596185568129984, 0.36429212911650116, 0.09002118362609146, 0.2131799719703972, 0.025244760737637054, 0.0853583867063481, 0.19398428505988233, -0.26681483839528725] ersetzt!\n",
      "der Bias: 0.3617651395243815 wird mit 0.3658101740126336 ersetzt!\n",
      "Error: -0.19589253623813163\n",
      "Gradients of neuron Nr.2: [-0.0008645912548744892, -0.0008645912548744892, -0.0008645912548744892, -0.0008645912548744892, -0.0008645912548744892, -0.0008645912548744892, -0.0008645912548744892, -0.0008645912548744892, -0.0008645912548744892]\n",
      "Die weights: [0.1668032520371253, 0.3150545470974215, 0.4580927591044503, -0.08780337578487288, -0.25644238037330463, -0.1415762994499277, 0.4222332554098635, -0.16665308825911543, -0.003704996424230419] werden mit den weights [0.16681189794967402, 0.3150631930099702, 0.45810140501699903, -0.08779472987232413, -0.2564337344607559, -0.14156765353737896, 0.42224190132241224, -0.1666444423465667, -0.003696350511681674] ersetzt!\n",
      "der Bias: -0.40101905211295064 wird mit -0.39906012675056934 ersetzt!\n",
      "Error: -0.0\n",
      "Gradients of neuron Nr.3: [-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0]\n",
      "Die weights: [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701] werden mit den weights [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701] ersetzt!\n",
      "der Bias: -0.4498036763391735 wird mit -0.4498036763391735 ersetzt!\n",
      "Error: -0.1609562631815123\n",
      "Gradients of neuron Nr.4: [-0.00013976475360609657, -0.00013976475360609657, -0.00013976475360609657, -0.00013976475360609657, -0.00013976475360609657, -0.00013976475360609657, -0.00013976475360609657, -0.00013976475360609657, -0.00013976475360609657]\n",
      "Die weights: [-0.0518965921843356, 0.10461951056249288, -0.3773736694239995, 0.27566280065166204, -0.45668972563643884, -0.458185308351013, 0.23996347277271482, 0.4184705759580033, 0.3294501339121828] werden mit den weights [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885] ersetzt!\n",
      "der Bias: -0.3097403323387301 wird mit -0.308130769706915 ersetzt!\n",
      "\n",
      " ---------- Layer 0 ---------- \n",
      "\n",
      "Netzwerk3: [[{'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}], [{'weights': [-0.20544659920651384, 0.22041596074936867, -0.21664100954767115, 0.16596239485320777, 0.09819642006558983, -0.39336468586048257, -0.4947725668058588, -0.36620293037543217, 0.15031366006512695], 'bias': 0.35248515051710183, 'activation': 0, 'error': -0.0}, {'weights': [0.054324852155775774, -0.4596185568129984, 0.36429212911650116, 0.09002118362609146, 0.2131799719703972, 0.025244760737637054, 0.0853583867063481, 0.19398428505988233, -0.26681483839528725], 'bias': 0.3617651395243815, 'activation': 0.5922752481037428, 'error': -0.40450344882521294}, {'weights': [0.16681189794967402, 0.3150631930099702, 0.45810140501699903, -0.08779472987232413, -0.2564337344607559, -0.14156765353737896, 0.42224190132241224, -0.1666444423465667, -0.003696350511681674], 'bias': -0.40101905211295064, 'activation': 0.10021407954916528, 'error': -0.19589253623813163}, {'weights': [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701], 'bias': -0.4498036763391735, 'activation': 0, 'error': -0.0}, {'weights': [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885], 'bias': -0.3097403323387301, 'activation': 0.15398934890131116, 'error': -0.1609562631815123}], [{'weights': [0.2779923402598486, -0.48707076029523183, 0.43255648738173486, 0.10915404387746323, 0.004170228314799549], 'bias': 0.42000886539078, 'activation': 0.1754378317560756, 'error': -0.554811775754615}, {'weights': [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852], 'bias': -0.39195604157641695, 'activation': 0, 'error': -0.0}, {'weights': [0.4572853572402668, -0.284997927821065, -0.15799004977976353, 0.08136361436105914, -0.4725888945716226], 'bias': 0.3567979477033839, 'activation': 0.09940179440425811, 'error': 0.0008141002106103884}, {'weights': [0.005610108288180055, -0.0529341452165885, -0.15341970811941313, 0.26899682561735316, -0.010414031676095819], 'bias': 0.3834499349685605, 'activation': 0.33518508488015414, 'error': -0.2320627471097811}, {'weights': [-0.44589104384082007, -0.3747744578302406, 0.43156501828896804, -0.4635331702492716, -0.026509006012604926], 'bias': 0.2676336062123419, 'activation': 0.0848495544840489, 'error': 0.25218586396737863}], [{'weights': [0.30132022609243514, 0.3602182782580192, 0.16958623545326557, -0.417982650843028, -0.4244168316598933], 'bias': -0.15625408839192734, 'activation': 0.5301828171457316, 'error': -0.5301828171457316}, {'weights': [-0.4142328467908393, -0.06056583429823085, 0.3586076284029395, -0.22347929382075055, 0.21127977628729794], 'bias': -0.29033269689943275, 'activation': 0.4698171828542684, 'error': 0.5301828171457317}]]\n",
      "**Iteration 5**\n",
      "\n",
      "========== FP ============\n",
      "Prediction: horizontal\n",
      "Netzwerk2: [[{'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}], [{'weights': [-0.20544659920651384, 0.22041596074936867, -0.21664100954767115, 0.16596239485320777, 0.09819642006558983, -0.39336468586048257, -0.4947725668058588, -0.36620293037543217, 0.15031366006512695], 'bias': 0.35248515051710183, 'activation': 0.1508135025122855, 'error': -0.0}, {'weights': [0.054324852155775774, -0.4596185568129984, 0.36429212911650116, 0.09002118362609146, 0.2131799719703972, 0.025244760737637054, 0.0853583867063481, 0.19398428505988233, -0.26681483839528725], 'bias': 0.3617651395243815, 'activation': 0.32076356398366, 'error': -0.40450344882521294}, {'weights': [0.16681189794967402, 0.3150631930099702, 0.45810140501699903, -0.08779472987232413, -0.2564337344607559, -0.14156765353737896, 0.42224190132241224, -0.1666444423465667, -0.003696350511681674], 'bias': -0.40101905211295064, 'activation': 0.5389574438636926, 'error': -0.19589253623813163}, {'weights': [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701], 'bias': -0.4498036763391735, 'activation': 0, 'error': -0.0}, {'weights': [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885], 'bias': -0.3097403323387301, 'activation': 0, 'error': -0.1609562631815123}], [{'weights': [0.2779923402598486, -0.48707076029523183, 0.43255648738173486, 0.10915404387746323, 0.004170228314799549], 'bias': 0.42000886539078, 'activation': 0.5388288496783427, 'error': -0.554811775754615}, {'weights': [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852], 'bias': -0.39195604157641695, 'activation': 0, 'error': -0.0}, {'weights': [0.4572853572402668, -0.284997927821065, -0.15799004977976353, 0.08136361436105914, -0.4725888945716226], 'bias': 0.3567979477033839, 'activation': 0.24919588963532868, 'error': 0.0008141002106103884}, {'weights': [0.005610108288180055, -0.0529341452165885, -0.15341970811941313, 0.26899682561735316, -0.010414031676095819], 'bias': 0.3834499349685605, 'activation': 0.28462997624651987, 'error': -0.2320627471097811}, {'weights': [-0.44589104384082007, -0.3747744578302406, 0.43156501828896804, -0.4635331702492716, -0.026509006012604926], 'bias': 0.2676336062123419, 'activation': 0.3127684044861868, 'error': 0.25218586396737863}], [{'weights': [0.30132022609243514, 0.3602182782580192, 0.16958623545326557, -0.417982650843028, -0.4244168316598933], 'bias': -0.15625408839192734, 'activation': 0.5543713022241885, 'error': -0.5301828171457316}, {'weights': [-0.4142328467908393, -0.06056583429823085, 0.3586076284029395, -0.22347929382075055, 0.21127977628729794], 'bias': -0.29033269689943275, 'activation': 0.4456286977758116, 'error': 0.5301828171457317}]]\n",
      "\n",
      "========== BP ============\n",
      "Cross Entropy Loss des Output layers: 0.5899205961111119\n",
      "\n",
      " ---------- Layer 3 ---------- \n",
      "\n",
      "Error: 0.4456286977758115\n",
      "Gradients of neuron Nr.0: [0.13695397176603785, 0.13695397176603785, 0.13695397176603785, 0.13695397176603785, 0.13695397176603785]\n",
      "Die weights: [0.30132022609243514, 0.3602182782580192, 0.16958623545326557, -0.417982650843028, -0.4244168316598933] werden mit den weights [0.29995068637477473, 0.3588487385403588, 0.1682166957356052, -0.4193521905606884, -0.4257863713775537] ersetzt!\n",
      "der Bias: -0.15625408839192734 wird mit -0.16071037536968547 ersetzt!\n",
      "Error: -0.4456286977758116\n",
      "Gradients of neuron Nr.1: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [-0.4142328467908393, -0.06056583429823085, 0.3586076284029395, -0.22347929382075055, 0.21127977628729794] werden mit den weights [-0.4142328467908393, -0.06056583429823085, 0.3586076284029395, -0.22347929382075055, 0.21127977628729794] ersetzt!\n",
      "der Bias: -0.29033269689943275 wird mit -0.2858764099216746 ersetzt!\n",
      "\n",
      " ---------- Layer 2 ---------- \n",
      "\n",
      "Error: -0.22056817182082195\n",
      "Gradients of neuron Nr.0: [0.04261345973061968, 0.04261345973061968, 0.04261345973061968, 0.04261345973061968, 0.04261345973061968]\n",
      "Die weights: [0.2779923402598486, -0.48707076029523183, 0.43255648738173486, 0.10915404387746323, 0.004170228314799549] werden mit den weights [0.2775662056625424, -0.487496894892538, 0.4321303527844287, 0.10872790928015703, 0.003744093717493352] ersetzt!\n",
      "der Bias: 0.42000886539078 wird mit 0.4222145471089882 ersetzt!\n",
      "Error: 0.0\n",
      "Gradients of neuron Nr.1: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852] werden mit den weights [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852] ersetzt!\n",
      "der Bias: -0.39195604157641695 wird mit -0.39195604157641695 ersetzt!\n",
      "Error: -0.3340395530281951\n",
      "Gradients of neuron Nr.2: [-0.003955740583896304, -0.003955740583896304, -0.003955740583896304, -0.003955740583896304, -0.003955740583896304]\n",
      "Die weights: [0.4572853572402668, -0.284997927821065, -0.15799004977976353, 0.08136361436105914, -0.4725888945716226] werden mit den weights [0.45732491464610575, -0.28495837041522604, -0.15795049237392456, 0.08140317176689811, -0.4725493371657837] ersetzt!\n",
      "der Bias: 0.3567979477033839 wird mit 0.36013834323366584 ersetzt!\n",
      "Error: -0.3719165601503143\n",
      "Gradients of neuron Nr.3: [-0.005058706792749333, -0.005058706792749333, -0.005058706792749333, -0.005058706792749333, -0.005058706792749333]\n",
      "Die weights: [0.005610108288180055, -0.0529341452165885, -0.15341970811941313, 0.26899682561735316, -0.010414031676095819] werden mit den weights [0.005660695356107548, -0.052883558148661004, -0.15336912105148565, 0.26904741268528065, -0.010363444608168326] ersetzt!\n",
      "der Bias: 0.3834499349685605 wird mit 0.38716910057006365 ersetzt!\n",
      "Error: -0.5966633622671276\n",
      "Gradients of neuron Nr.4: [-0.019085632033246154, -0.019085632033246154, -0.019085632033246154, -0.019085632033246154, -0.019085632033246154]\n",
      "Die weights: [-0.44589104384082007, -0.3747744578302406, 0.43156501828896804, -0.4635331702492716, -0.026509006012604926] werden mit den weights [-0.4457001875204876, -0.37458360150990816, 0.4317558746093005, -0.46334231392893915, -0.026318149692272464] ersetzt!\n",
      "der Bias: 0.2676336062123419 wird mit 0.2736002398350132 ersetzt!\n",
      "\n",
      " ---------- Layer 1 ---------- \n",
      "\n",
      "Error: -0.10097271702739641\n",
      "Gradients of neuron Nr.0: [0.0009626499897169144, 0.0009626499897169144, 0.0009626499897169144, 0.0009626499897169144, 0.0009626499897169144, 0.0009626499897169144, 0.0009626499897169144, 0.0009626499897169144, 0.0009626499897169144]\n",
      "Die weights: [-0.20544659920651384, 0.22041596074936867, -0.21664100954767115, 0.16596239485320777, 0.09819642006558983, -0.39336468586048257, -0.4947725668058588, -0.36620293037543217, 0.15031366006512695] werden mit den weights [-0.205456225706411, 0.2204063342494715, -0.21665063604756832, 0.1659527683533106, 0.09818679356569267, -0.39337431236037973, -0.49478219330575596, -0.36621255687532933, 0.15030403356522978] ersetzt!\n",
      "der Bias: 0.35248515051710183 wird mit 0.3534948776873758 ersetzt!\n",
      "Error: 0.12511868373845025\n",
      "Gradients of neuron Nr.1: [0.031160987836700627, 0.031160987836700627, 0.031160987836700627, 0.031160987836700627, 0.031160987836700627, 0.031160987836700627, 0.031160987836700627, 0.031160987836700627, 0.031160987836700627]\n",
      "Die weights: [0.054324852155775774, -0.4596185568129984, 0.36429212911650116, 0.09002118362609146, 0.2131799719703972, 0.025244760737637054, 0.0853583867063481, 0.19398428505988233, -0.26681483839528725] werden mit den weights [0.054013242277408766, -0.4599301666913654, 0.3639805192381342, 0.08970957374772445, 0.2128683620920302, 0.02493315085927005, 0.08504677682798109, 0.19367267518151532, -0.2671264482736542] ersetzt!\n",
      "der Bias: 0.3617651395243815 wird mit 0.360513952686997 ersetzt!\n",
      "Error: -0.7820823297806956\n",
      "Gradients of neuron Nr.2: [-0.03255962381352616, -0.03255962381352616, -0.03255962381352616, -0.03255962381352616, -0.03255962381352616, -0.03255962381352616, -0.03255962381352616, -0.03255962381352616, -0.03255962381352616]\n",
      "Die weights: [0.16681189794967402, 0.3150631930099702, 0.45810140501699903, -0.08779472987232413, -0.2564337344607559, -0.14156765353737896, 0.42224190132241224, -0.1666444423465667, -0.003696350511681674] werden mit den weights [0.1671374941878093, 0.3153887892481055, 0.4584270012551343, -0.08746913363418887, -0.25610813822262063, -0.1412420572992437, 0.4225674975605475, -0.16631884610843142, -0.0033707542735464126] ersetzt!\n",
      "der Bias: -0.40101905211295064 wird mit -0.39319822881514366 ersetzt!\n",
      "Error: 0.0\n",
      "Gradients of neuron Nr.3: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701] werden mit den weights [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701] ersetzt!\n",
      "der Bias: -0.4498036763391735 wird mit -0.4498036763391735 ersetzt!\n",
      "Error: 0.0\n",
      "Gradients of neuron Nr.4: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885] werden mit den weights [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885] ersetzt!\n",
      "der Bias: -0.3097403323387301 wird mit -0.3097403323387301 ersetzt!\n",
      "\n",
      " ---------- Layer 0 ---------- \n",
      "\n",
      "Netzwerk3: [[{'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}], [{'weights': [-0.205456225706411, 0.2204063342494715, -0.21665063604756832, 0.1659527683533106, 0.09818679356569267, -0.39337431236037973, -0.49478219330575596, -0.36621255687532933, 0.15030403356522978], 'bias': 0.35248515051710183, 'activation': 0.1508135025122855, 'error': -0.10097271702739641}, {'weights': [0.054013242277408766, -0.4599301666913654, 0.3639805192381342, 0.08970957374772445, 0.2128683620920302, 0.02493315085927005, 0.08504677682798109, 0.19367267518151532, -0.2671264482736542], 'bias': 0.3617651395243815, 'activation': 0.32076356398366, 'error': 0.12511868373845025}, {'weights': [0.1671374941878093, 0.3153887892481055, 0.4584270012551343, -0.08746913363418887, -0.25610813822262063, -0.1412420572992437, 0.4225674975605475, -0.16631884610843142, -0.0033707542735464126], 'bias': -0.40101905211295064, 'activation': 0.5389574438636926, 'error': -0.7820823297806956}, {'weights': [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701], 'bias': -0.4498036763391735, 'activation': 0, 'error': 0.0}, {'weights': [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885], 'bias': -0.3097403323387301, 'activation': 0, 'error': 0.0}], [{'weights': [0.2775662056625424, -0.487496894892538, 0.4321303527844287, 0.10872790928015703, 0.003744093717493352], 'bias': 0.42000886539078, 'activation': 0.5388288496783427, 'error': -0.22056817182082195}, {'weights': [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852], 'bias': -0.39195604157641695, 'activation': 0, 'error': 0.0}, {'weights': [0.45732491464610575, -0.28495837041522604, -0.15795049237392456, 0.08140317176689811, -0.4725493371657837], 'bias': 0.3567979477033839, 'activation': 0.24919588963532868, 'error': -0.3340395530281951}, {'weights': [0.005660695356107548, -0.052883558148661004, -0.15336912105148565, 0.26904741268528065, -0.010363444608168326], 'bias': 0.3834499349685605, 'activation': 0.28462997624651987, 'error': -0.3719165601503143}, {'weights': [-0.4457001875204876, -0.37458360150990816, 0.4317558746093005, -0.46334231392893915, -0.026318149692272464], 'bias': 0.2676336062123419, 'activation': 0.3127684044861868, 'error': -0.5966633622671276}], [{'weights': [0.29995068637477473, 0.3588487385403588, 0.1682166957356052, -0.4193521905606884, -0.4257863713775537], 'bias': -0.15625408839192734, 'activation': 0.5543713022241885, 'error': 0.4456286977758115}, {'weights': [-0.4142328467908393, -0.06056583429823085, 0.3586076284029395, -0.22347929382075055, 0.21127977628729794], 'bias': -0.29033269689943275, 'activation': 0.4456286977758116, 'error': -0.4456286977758116}]]\n",
      "**Iteration 6**\n",
      "\n",
      "========== FP ============\n",
      "Prediction: horizontal\n",
      "Netzwerk2: [[{'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}], [{'weights': [-0.205456225706411, 0.2204063342494715, -0.21665063604756832, 0.1659527683533106, 0.09818679356569267, -0.39337431236037973, -0.49478219330575596, -0.36621255687532933, 0.15030403356522978], 'bias': 0.35248515051710183, 'activation': 0, 'error': -0.10097271702739641}, {'weights': [0.054013242277408766, -0.4599301666913654, 0.3639805192381342, 0.08970957374772445, 0.2128683620920302, 0.02493315085927005, 0.08504677682798109, 0.19367267518151532, -0.2671264482736542], 'bias': 0.3617651395243815, 'activation': 0.4835523613481315, 'error': 0.12511868373845025}, {'weights': [0.1671374941878093, 0.3153887892481055, 0.4584270012551343, -0.08746913363418887, -0.25610813822262063, -0.1412420572992437, 0.4225674975605475, -0.16631884610843142, -0.0033707542735464126], 'bias': -0.40101905211295064, 'activation': 0, 'error': -0.7820823297806956}, {'weights': [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701], 'bias': -0.4498036763391735, 'activation': 0.09422592948410935, 'error': 0.0}, {'weights': [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885], 'bias': -0.3097403323387301, 'activation': 0, 'error': 0.0}], [{'weights': [0.2775662056625424, -0.487496894892538, 0.4321303527844287, 0.10872790928015703, 0.003744093717493352], 'bias': 0.42000886539078, 'activation': 0.19452357902839806, 'error': -0.22056817182082195}, {'weights': [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852], 'bias': -0.39195604157641695, 'activation': 0, 'error': 0.0}, {'weights': [0.45732491464610575, -0.28495837041522604, -0.15795049237392456, 0.08140317176689811, -0.4725493371657837], 'bias': 0.3567979477033839, 'activation': 0.2266759443258764, 'error': -0.3340395530281951}, {'weights': [0.005660695356107548, -0.052883558148661004, -0.15336912105148565, 0.26904741268528065, -0.010363444608168326], 'bias': 0.3834499349685605, 'activation': 0.38322920808484956, 'error': -0.3719165601503143}, {'weights': [-0.4457001875204876, -0.37458360150990816, 0.4317558746093005, -0.46334231392893915, -0.026318149692272464], 'bias': 0.2676336062123419, 'activation': 0.04284396098066598, 'error': -0.5966633622671276}], [{'weights': [0.29995068637477473, 0.3588487385403588, 0.1682166957356052, -0.4193521905606884, -0.4257863713775537], 'bias': -0.15625408839192734, 'activation': 0.5318290133029564, 'error': 0.4456286977758115}, {'weights': [-0.4142328467908393, -0.06056583429823085, 0.3586076284029395, -0.22347929382075055, 0.21127977628729794], 'bias': -0.29033269689943275, 'activation': 0.4681709866970437, 'error': -0.4456286977758116}]]\n",
      "\n",
      "========== BP ============\n",
      "Cross Entropy Loss des Output layers: 0.7589216936005467\n",
      "\n",
      " ---------- Layer 3 ---------- \n",
      "\n",
      "Error: -0.5318290133029564\n",
      "Gradients of neuron Nr.0: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [0.29995068637477473, 0.3588487385403588, 0.1682166957356052, -0.4193521905606884, -0.4257863713775537] werden mit den weights [0.29995068637477473, 0.3588487385403588, 0.1682166957356052, -0.4193521905606884, -0.4257863713775537] ersetzt!\n",
      "der Bias: -0.15625408839192734 wird mit -0.15093579825889777 ersetzt!\n",
      "Error: 0.5318290133029563\n",
      "Gradients of neuron Nr.1: [0.11656844916090794, 0.11656844916090794, 0.11656844916090794, 0.11656844916090794, 0.11656844916090794]\n",
      "Die weights: [-0.4142328467908393, -0.06056583429823085, 0.3586076284029395, -0.22347929382075055, 0.21127977628729794] werden mit den weights [-0.4153985312824484, -0.06173151878983993, 0.35744194391133044, -0.22464497831235963, 0.21011409179568885] ersetzt!\n",
      "der Bias: -0.29033269689943275 wird mit -0.2956509870324623 ersetzt!\n",
      "\n",
      " ---------- Layer 2 ---------- \n",
      "\n",
      "Error: -0.5749670476220807\n",
      "Gradients of neuron Nr.0: [-0.011595446255948699, -0.011595446255948699, -0.011595446255948699, -0.011595446255948699, -0.011595446255948699]\n",
      "Die weights: [0.2775662056625424, -0.487496894892538, 0.4321303527844287, 0.10872790928015703, 0.003744093717493352] werden mit den weights [0.2776821601251019, -0.48738094042997854, 0.43224630724698815, 0.10884386374271653, 0.003860048180052839] ersetzt!\n",
      "der Bias: 0.42000886539078 wird mit 0.4257585358670008 ersetzt!\n",
      "Error: -0.0\n",
      "Gradients of neuron Nr.1: [-0.0, -0.0, -0.0, -0.0, -0.0]\n",
      "Die weights: [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852] werden mit den weights [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852] ersetzt!\n",
      "der Bias: -0.39195604157641695 wird mit -0.39195604157641695 ersetzt!\n",
      "Error: -0.12604046729657342\n",
      "Gradients of neuron Nr.2: [0.003998743036628405, 0.003998743036628405, 0.003998743036628405, 0.003998743036628405, 0.003998743036628405]\n",
      "Die weights: [0.45732491464610575, -0.28495837041522604, -0.15795049237392456, 0.08140317176689811, -0.4725493371657837] werden mit den weights [0.4572849272157395, -0.2849983578455923, -0.15799047980429085, 0.08136318433653182, -0.47258932459614994] ersetzt!\n",
      "der Bias: 0.3567979477033839 wird mit 0.35805835237634964 ersetzt!\n",
      "Error: -0.27967826351185154\n",
      "Gradients of neuron Nr.3: [0.009379832156327185, 0.009379832156327185, 0.009379832156327185, 0.009379832156327185, 0.009379832156327185]\n",
      "Die weights: [0.005660695356107548, -0.052883558148661004, -0.15336912105148565, 0.26904741268528065, -0.010363444608168326] werden mit den weights [0.005566897034544277, -0.05297735647022428, -0.15346291937304893, 0.2689536143637174, -0.010457242929731598] ersetzt!\n",
      "der Bias: 0.3834499349685605 wird mit 0.386246717603679 ersetzt!\n",
      "Error: 0.2953463549076525\n",
      "Gradients of neuron Nr.4: [0.0005941869939771372, 0.0005941869939771372, 0.0005941869939771372, 0.0005941869939771372, 0.0005941869939771372]\n",
      "Die weights: [-0.4457001875204876, -0.37458360150990816, 0.4317558746093005, -0.46334231392893915, -0.026318149692272464] werden mit den weights [-0.4457061293904274, -0.37458954337984796, 0.4317499327393607, -0.46334825579887895, -0.026324091562212236] ersetzt!\n",
      "der Bias: 0.2676336062123419 wird mit 0.26468014266326534 ersetzt!\n",
      "\n",
      " ---------- Layer 1 ---------- \n",
      "\n",
      "Error: -0.0\n",
      "Gradients of neuron Nr.0: [-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0]\n",
      "Die weights: [-0.205456225706411, 0.2204063342494715, -0.21665063604756832, 0.1659527683533106, 0.09818679356569267, -0.39337431236037973, -0.49478219330575596, -0.36621255687532933, 0.15030403356522978] werden mit den weights [-0.205456225706411, 0.2204063342494715, -0.21665063604756832, 0.1659527683533106, 0.09818679356569267, -0.39337431236037973, -0.49478219330575596, -0.36621255687532933, 0.15030403356522978] ersetzt!\n",
      "der Bias: 0.35248515051710183 wird mit 0.35248515051710183 ersetzt!\n",
      "Error: -0.2632200959209384\n",
      "Gradients of neuron Nr.1: [0.026606724501399157, 0.026606724501399157, 0.026606724501399157, 0.026606724501399157, 0.026606724501399157, 0.026606724501399157, 0.026606724501399157, 0.026606724501399157, 0.026606724501399157]\n",
      "Die weights: [0.054013242277408766, -0.4599301666913654, 0.3639805192381342, 0.08970957374772445, 0.2128683620920302, 0.02493315085927005, 0.08504677682798109, 0.19367267518151532, -0.2671264482736542] werden mit den weights [0.053747175032394776, -0.4601962339363794, 0.3637144519931202, 0.08944350650271046, 0.2126022948470162, 0.02466708361425606, 0.0847807095829671, 0.19340660793650133, -0.2673925155186682] ersetzt!\n",
      "der Bias: 0.3617651395243815 wird mit 0.3643973404835909 ersetzt!\n",
      "Error: -0.0\n",
      "Gradients of neuron Nr.2: [-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0]\n",
      "Die weights: [0.1671374941878093, 0.3153887892481055, 0.4584270012551343, -0.08746913363418887, -0.25610813822262063, -0.1412420572992437, 0.4225674975605475, -0.16631884610843142, -0.0033707542735464126] werden mit den weights [0.1671374941878093, 0.3153887892481055, 0.4584270012551343, -0.08746913363418887, -0.25610813822262063, -0.1412420572992437, 0.4225674975605475, -0.16631884610843142, -0.0033707542735464126] ersetzt!\n",
      "der Bias: -0.40101905211295064 wird mit -0.40101905211295064 ersetzt!\n",
      "Error: -0.37913131648005094\n",
      "Gradients of neuron Nr.3: [-0.0022911915841300925, -0.0022911915841300925, -0.0022911915841300925, -0.0022911915841300925, -0.0022911915841300925, -0.0022911915841300925, -0.0022911915841300925, -0.0022911915841300925, -0.0022911915841300925]\n",
      "Die weights: [-0.4543958204616001, -0.17017750866617398, 0.49229606706034934, -0.2580785218942031, 0.061210799781829084, 0.028821541843463416, 0.06968760304088095, -0.4556274157762208, 0.0229119969194701] werden mit den weights [-0.4543729085457588, -0.17015459675033268, 0.49231897897619065, -0.2580556099783618, 0.06123371169767038, 0.02884445375930472, 0.06971051495672226, -0.4556045038603795, 0.022934908835311404] ersetzt!\n",
      "der Bias: -0.4498036763391735 wird mit -0.446012363174373 ersetzt!\n",
      "Error: 0.0\n",
      "Gradients of neuron Nr.4: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885] werden mit den weights [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885] ersetzt!\n",
      "der Bias: -0.3097403323387301 wird mit -0.3097403323387301 ersetzt!\n",
      "\n",
      " ---------- Layer 0 ---------- \n",
      "\n",
      "Netzwerk3: [[{'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}], [{'weights': [-0.205456225706411, 0.2204063342494715, -0.21665063604756832, 0.1659527683533106, 0.09818679356569267, -0.39337431236037973, -0.49478219330575596, -0.36621255687532933, 0.15030403356522978], 'bias': 0.35248515051710183, 'activation': 0, 'error': -0.0}, {'weights': [0.053747175032394776, -0.4601962339363794, 0.3637144519931202, 0.08944350650271046, 0.2126022948470162, 0.02466708361425606, 0.0847807095829671, 0.19340660793650133, -0.2673925155186682], 'bias': 0.3617651395243815, 'activation': 0.4835523613481315, 'error': -0.2632200959209384}, {'weights': [0.1671374941878093, 0.3153887892481055, 0.4584270012551343, -0.08746913363418887, -0.25610813822262063, -0.1412420572992437, 0.4225674975605475, -0.16631884610843142, -0.0033707542735464126], 'bias': -0.40101905211295064, 'activation': 0, 'error': -0.0}, {'weights': [-0.4543729085457588, -0.17015459675033268, 0.49231897897619065, -0.2580556099783618, 0.06123371169767038, 0.02884445375930472, 0.06971051495672226, -0.4556045038603795, 0.022934908835311404], 'bias': -0.4498036763391735, 'activation': 0.09422592948410935, 'error': -0.37913131648005094}, {'weights': [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885], 'bias': -0.3097403323387301, 'activation': 0, 'error': 0.0}], [{'weights': [0.2776821601251019, -0.48738094042997854, 0.43224630724698815, 0.10884386374271653, 0.003860048180052839], 'bias': 0.42000886539078, 'activation': 0.19452357902839806, 'error': -0.5749670476220807}, {'weights': [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852], 'bias': -0.39195604157641695, 'activation': 0, 'error': -0.0}, {'weights': [0.4572849272157395, -0.2849983578455923, -0.15799047980429085, 0.08136318433653182, -0.47258932459614994], 'bias': 0.3567979477033839, 'activation': 0.2266759443258764, 'error': -0.12604046729657342}, {'weights': [0.005566897034544277, -0.05297735647022428, -0.15346291937304893, 0.2689536143637174, -0.010457242929731598], 'bias': 0.3834499349685605, 'activation': 0.38322920808484956, 'error': -0.27967826351185154}, {'weights': [-0.4457061293904274, -0.37458954337984796, 0.4317499327393607, -0.46334825579887895, -0.026324091562212236], 'bias': 0.2676336062123419, 'activation': 0.04284396098066598, 'error': 0.2953463549076525}], [{'weights': [0.29995068637477473, 0.3588487385403588, 0.1682166957356052, -0.4193521905606884, -0.4257863713775537], 'bias': -0.15625408839192734, 'activation': 0.5318290133029564, 'error': -0.5318290133029564}, {'weights': [-0.4153985312824484, -0.06173151878983993, 0.35744194391133044, -0.22464497831235963, 0.21011409179568885], 'bias': -0.29033269689943275, 'activation': 0.4681709866970437, 'error': 0.5318290133029563}]]\n",
      "**Iteration 7**\n",
      "\n",
      "========== FP ============\n",
      "Prediction: horizontal\n",
      "Netzwerk2: [[{'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}], [{'weights': [-0.205456225706411, 0.2204063342494715, -0.21665063604756832, 0.1659527683533106, 0.09818679356569267, -0.39337431236037973, -0.49478219330575596, -0.36621255687532933, 0.15030403356522978], 'bias': 0.35248515051710183, 'activation': 0, 'error': -0.0}, {'weights': [0.053747175032394776, -0.4601962339363794, 0.3637144519931202, 0.08944350650271046, 0.2126022948470162, 0.02466708361425606, 0.0847807095829671, 0.19340660793650133, -0.2673925155186682], 'bias': 0.3617651395243815, 'activation': 0.48275415961308954, 'error': -0.2632200959209384}, {'weights': [0.1671374941878093, 0.3153887892481055, 0.4584270012551343, -0.08746913363418887, -0.25610813822262063, -0.1412420572992437, 0.4225674975605475, -0.16631884610843142, -0.0033707542735464126], 'bias': -0.40101905211295064, 'activation': 0, 'error': -0.0}, {'weights': [-0.4543729085457588, -0.17015459675033268, 0.49231897897619065, -0.2580556099783618, 0.06123371169767038, 0.02884445375930472, 0.06971051495672226, -0.4556045038603795, 0.022934908835311404], 'bias': -0.4498036763391735, 'activation': 0.09429466523163321, 'error': -0.37913131648005094}, {'weights': [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885], 'bias': -0.3097403323387301, 'activation': 0, 'error': 0.0}], [{'weights': [0.2776821601251019, -0.48738094042997854, 0.43224630724698815, 0.10884386374271653, 0.003860048180052839], 'bias': 0.42000886539078, 'activation': 0.19498708477620538, 'error': -0.5749670476220807}, {'weights': [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852], 'bias': -0.39195604157641695, 'activation': 0, 'error': -0.0}, {'weights': [0.4572849272157395, -0.2849983578455923, -0.15799047980429085, 0.08136318433653182, -0.47258932459614994], 'bias': 0.3567979477033839, 'activation': 0.22688591919971737, 'error': -0.12604046729657342}, {'weights': [0.005566897034544277, -0.05297735647022428, -0.15346291937304893, 0.2689536143637174, -0.010457242929731598], 'bias': 0.3834499349685605, 'activation': 0.3832357867965188, 'error': -0.27967826351185154}, {'weights': [-0.4457061293904274, -0.37458954337984796, 0.4317499327393607, -0.46334825579887895, -0.026324091562212236], 'bias': 0.2676336062123419, 'activation': 0.04310767733193599, 'error': 0.2953463549076525}], [{'weights': [0.29995068637477473, 0.3588487385403588, 0.1682166957356052, -0.4193521905606884, -0.4257863713775537], 'bias': -0.15625408839192734, 'activation': 0.5321055060318913, 'error': -0.5318290133029564}, {'weights': [-0.4153985312824484, -0.06173151878983993, 0.35744194391133044, -0.22464497831235963, 0.21011409179568885], 'bias': -0.29033269689943275, 'activation': 0.46789449396810867, 'error': 0.5318290133029563}]]\n",
      "\n",
      "========== BP ============\n",
      "Cross Entropy Loss des Output layers: 0.7595124487190449\n",
      "\n",
      " ---------- Layer 3 ---------- \n",
      "\n",
      "Error: -0.5321055060318913\n",
      "Gradients of neuron Nr.0: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [0.29995068637477473, 0.3588487385403588, 0.1682166957356052, -0.4193521905606884, -0.4257863713775537] werden mit den weights [0.29995068637477473, 0.3588487385403588, 0.1682166957356052, -0.4193521905606884, -0.4257863713775537] ersetzt!\n",
      "der Bias: -0.15625408839192734 wird mit -0.15093303333160843 ersetzt!\n",
      "Error: 0.5321055060318913\n",
      "Gradients of neuron Nr.1: [0.11649133491757586, 0.11649133491757586, 0.11649133491757586, 0.11649133491757586, 0.11649133491757586]\n",
      "Die weights: [-0.4153985312824484, -0.06173151878983993, 0.35744194391133044, -0.22464497831235963, 0.21011409179568885] werden mit den weights [-0.41656344463162415, -0.06289643213901569, 0.3562770305621547, -0.2258098916615354, 0.2089491784465131] ersetzt!\n",
      "der Bias: -0.29033269689943275 wird mit -0.2956537519597517 ersetzt!\n",
      "\n",
      " ---------- Layer 2 ---------- \n",
      "\n",
      "Error: -0.5762481990343662\n",
      "Gradients of neuron Nr.0: [-0.01166909171673829, -0.01166909171673829, -0.01166909171673829, -0.01166909171673829, -0.01166909171673829]\n",
      "Die weights: [0.2776821601251019, -0.48738094042997854, 0.43224630724698815, 0.10884386374271653, 0.003860048180052839] werden mit den weights [0.27779885104226926, -0.48726424951281117, 0.4323629981641555, 0.10896055465988391, 0.003976739097220222] ersetzt!\n",
      "der Bias: 0.42000886539078 wird mit 0.42577134738112365 ersetzt!\n",
      "Error: -0.0\n",
      "Gradients of neuron Nr.1: [-0.0, -0.0, -0.0, -0.0, -0.0]\n",
      "Die weights: [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852] werden mit den weights [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852] ersetzt!\n",
      "der Bias: -0.39195604157641695 wird mit -0.39195604157641695 ersetzt!\n",
      "Error: -0.12681797957230934\n",
      "Gradients of neuron Nr.2: [0.003982480233092826, 0.003982480233092826, 0.003982480233092826, 0.003982480233092826, 0.003982480233092826]\n",
      "Die weights: [0.4572849272157395, -0.2849983578455923, -0.15799047980429085, 0.08136318433653182, -0.47258932459614994] werden mit den weights [0.45724510241340854, -0.28503818264792324, -0.15803030460662176, 0.08132335953420089, -0.4726291493984809] ersetzt!\n",
      "der Bias: 0.3567979477033839 wird mit 0.358066127499107 ersetzt!\n",
      "Error: -0.28025086390220943\n",
      "Gradients of neuron Nr.3: [0.009328781662446365, 0.009328781662446365, 0.009328781662446365, 0.009328781662446365, 0.009328781662446365]\n",
      "Die weights: [0.005566897034544277, -0.05297735647022428, -0.15346291937304893, 0.2689536143637174, -0.010457242929731598] werden mit den weights [0.005473609217919813, -0.053070644286848746, -0.1535562071896734, 0.2688603265470929, -0.010550530746356061] ersetzt!\n",
      "der Bias: 0.3834499349685605 wird mit 0.3862524436075826 ersetzt!\n",
      "Error: 0.29463860360362987\n",
      "Gradients of neuron Nr.4: [0.0006005689742814192, 0.0006005689742814192, 0.0006005689742814192, 0.0006005689742814192, 0.0006005689742814192]\n",
      "Die weights: [-0.4457061293904274, -0.37458954337984796, 0.4317499327393607, -0.46334825579887895, -0.026324091562212236] werden mit den weights [-0.4457121350801702, -0.37459554906959075, 0.4317439270496179, -0.46335426148862174, -0.02633009725195505] ersetzt!\n",
      "der Bias: 0.2676336062123419 wird mit 0.2646872201763056 ersetzt!\n",
      "\n",
      " ---------- Layer 1 ---------- \n",
      "\n",
      "Error: -0.0\n",
      "Gradients of neuron Nr.0: [-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0]\n",
      "Die weights: [-0.205456225706411, 0.2204063342494715, -0.21665063604756832, 0.1659527683533106, 0.09818679356569267, -0.39337431236037973, -0.49478219330575596, -0.36621255687532933, 0.15030403356522978] werden mit den weights [-0.205456225706411, 0.2204063342494715, -0.21665063604756832, 0.1659527683533106, 0.09818679356569267, -0.39337431236037973, -0.49478219330575596, -0.36621255687532933, 0.15030403356522978] ersetzt!\n",
      "der Bias: 0.35248515051710183 wird mit 0.35248515051710183 ersetzt!\n",
      "Error: -0.2613182625378906\n",
      "Gradients of neuron Nr.1: [0.026692981275496432, 0.026692981275496432, 0.026692981275496432, 0.026692981275496432, 0.026692981275496432, 0.026692981275496432, 0.026692981275496432, 0.026692981275496432, 0.026692981275496432]\n",
      "Die weights: [0.053747175032394776, -0.4601962339363794, 0.3637144519931202, 0.08944350650271046, 0.2126022948470162, 0.02466708361425606, 0.0847807095829671, 0.19340660793650133, -0.2673925155186682] werden mit den weights [0.05348024521963981, -0.4604631637491343, 0.36344752218036525, 0.0891765766899555, 0.21233536503426123, 0.024400153801501095, 0.08451377977021214, 0.19313967812374636, -0.26765944533142316] ersetzt!\n",
      "der Bias: 0.3617651395243815 wird mit 0.3643783221497604 ersetzt!\n",
      "Error: -0.0\n",
      "Gradients of neuron Nr.2: [-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0]\n",
      "Die weights: [0.1671374941878093, 0.3153887892481055, 0.4584270012551343, -0.08746913363418887, -0.25610813822262063, -0.1412420572992437, 0.4225674975605475, -0.16631884610843142, -0.0033707542735464126] werden mit den weights [0.1671374941878093, 0.3153887892481055, 0.4584270012551343, -0.08746913363418887, -0.25610813822262063, -0.1412420572992437, 0.4225674975605475, -0.16631884610843142, -0.0033707542735464126] ersetzt!\n",
      "der Bias: -0.40101905211295064 wird mit -0.40101905211295064 ersetzt!\n",
      "Error: -0.3792666441309884\n",
      "Gradients of neuron Nr.3: [-0.0022948976966241626, -0.0022948976966241626, -0.0022948976966241626, -0.0022948976966241626, -0.0022948976966241626, -0.0022948976966241626, -0.0022948976966241626, -0.0022948976966241626, -0.0022948976966241626]\n",
      "Die weights: [-0.4543729085457588, -0.17015459675033268, 0.49231897897619065, -0.2580556099783618, 0.06123371169767038, 0.02884445375930472, 0.06971051495672226, -0.4556045038603795, 0.022934908835311404] werden mit den weights [-0.45434995956879254, -0.17013164777336642, 0.4923419279531569, -0.25803266100139555, 0.06125666067463662, 0.02886740273627096, 0.0697334639336885, -0.45558155488341323, 0.022957857812277646] ersetzt!\n",
      "der Bias: -0.4498036763391735 wird mit -0.44601100989786363 ersetzt!\n",
      "Error: 0.0\n",
      "Gradients of neuron Nr.4: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885] werden mit den weights [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885] ersetzt!\n",
      "der Bias: -0.3097403323387301 wird mit -0.3097403323387301 ersetzt!\n",
      "\n",
      " ---------- Layer 0 ---------- \n",
      "\n",
      "Netzwerk3: [[{'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}], [{'weights': [-0.205456225706411, 0.2204063342494715, -0.21665063604756832, 0.1659527683533106, 0.09818679356569267, -0.39337431236037973, -0.49478219330575596, -0.36621255687532933, 0.15030403356522978], 'bias': 0.35248515051710183, 'activation': 0, 'error': -0.0}, {'weights': [0.05348024521963981, -0.4604631637491343, 0.36344752218036525, 0.0891765766899555, 0.21233536503426123, 0.024400153801501095, 0.08451377977021214, 0.19313967812374636, -0.26765944533142316], 'bias': 0.3617651395243815, 'activation': 0.48275415961308954, 'error': -0.2613182625378906}, {'weights': [0.1671374941878093, 0.3153887892481055, 0.4584270012551343, -0.08746913363418887, -0.25610813822262063, -0.1412420572992437, 0.4225674975605475, -0.16631884610843142, -0.0033707542735464126], 'bias': -0.40101905211295064, 'activation': 0, 'error': -0.0}, {'weights': [-0.45434995956879254, -0.17013164777336642, 0.4923419279531569, -0.25803266100139555, 0.06125666067463662, 0.02886740273627096, 0.0697334639336885, -0.45558155488341323, 0.022957857812277646], 'bias': -0.4498036763391735, 'activation': 0.09429466523163321, 'error': -0.3792666441309884}, {'weights': [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885], 'bias': -0.3097403323387301, 'activation': 0, 'error': 0.0}], [{'weights': [0.27779885104226926, -0.48726424951281117, 0.4323629981641555, 0.10896055465988391, 0.003976739097220222], 'bias': 0.42000886539078, 'activation': 0.19498708477620538, 'error': -0.5762481990343662}, {'weights': [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852], 'bias': -0.39195604157641695, 'activation': 0, 'error': -0.0}, {'weights': [0.45724510241340854, -0.28503818264792324, -0.15803030460662176, 0.08132335953420089, -0.4726291493984809], 'bias': 0.3567979477033839, 'activation': 0.22688591919971737, 'error': -0.12681797957230934}, {'weights': [0.005473609217919813, -0.053070644286848746, -0.1535562071896734, 0.2688603265470929, -0.010550530746356061], 'bias': 0.3834499349685605, 'activation': 0.3832357867965188, 'error': -0.28025086390220943}, {'weights': [-0.4457121350801702, -0.37459554906959075, 0.4317439270496179, -0.46335426148862174, -0.02633009725195505], 'bias': 0.2676336062123419, 'activation': 0.04310767733193599, 'error': 0.29463860360362987}], [{'weights': [0.29995068637477473, 0.3588487385403588, 0.1682166957356052, -0.4193521905606884, -0.4257863713775537], 'bias': -0.15625408839192734, 'activation': 0.5321055060318913, 'error': -0.5321055060318913}, {'weights': [-0.41656344463162415, -0.06289643213901569, 0.3562770305621547, -0.2258098916615354, 0.2089491784465131], 'bias': -0.29033269689943275, 'activation': 0.46789449396810867, 'error': 0.5321055060318913}]]\n",
      "**Iteration 8**\n",
      "\n",
      "========== FP ============\n",
      "Prediction: horizontal\n",
      "Netzwerk2: [[{'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}], [{'weights': [-0.205456225706411, 0.2204063342494715, -0.21665063604756832, 0.1659527683533106, 0.09818679356569267, -0.39337431236037973, -0.49478219330575596, -0.36621255687532933, 0.15030403356522978], 'bias': 0.35248515051710183, 'activation': 0.22325040007572539, 'error': -0.0}, {'weights': [0.05348024521963981, -0.4604631637491343, 0.36344752218036525, 0.0891765766899555, 0.21233536503426123, 0.024400153801501095, 0.08451377977021214, 0.19313967812374636, -0.26765944533142316], 'bias': 0.3617651395243815, 'activation': 0.6876772350500993, 'error': -0.2613182625378906}, {'weights': [0.1671374941878093, 0.3153887892481055, 0.4584270012551343, -0.08746913363418887, -0.25610813822262063, -0.1412420572992437, 0.4225674975605475, -0.16631884610843142, -0.0033707542735464126], 'bias': -0.40101905211295064, 'activation': 0, 'error': -0.0}, {'weights': [-0.45434995956879254, -0.17013164777336642, 0.4923419279531569, -0.25803266100139555, 0.06125666067463662, 0.02886740273627096, 0.0697334639336885, -0.45558155488341323, 0.022957857812277646], 'bias': -0.4498036763391735, 'activation': 0, 'error': -0.3792666441309884}, {'weights': [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885], 'bias': -0.3097403323387301, 'activation': 0, 'error': 0.0}], [{'weights': [0.27779885104226926, -0.48726424951281117, 0.4323629981641555, 0.10896055465988391, 0.003976739097220222], 'bias': 0.42000886539078, 'activation': 0.1469470381828118, 'error': -0.5762481990343662}, {'weights': [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852], 'bias': -0.39195604157641695, 'activation': 0, 'error': -0.0}, {'weights': [0.45724510241340854, -0.28503818264792324, -0.15803030460662176, 0.08132335953420089, -0.4726291493984809], 'bias': 0.3567979477033839, 'activation': 0.26286383042281436, 'error': -0.12681797957230934}, {'weights': [0.005473609217919813, -0.053070644286848746, -0.1535562071896734, 0.2688603265470929, -0.010550530746356061], 'bias': 0.3834499349685605, 'activation': 0.3481764464908118, 'error': -0.28025086390220943}, {'weights': [-0.4457121350801702, -0.37459554906959075, 0.4317439270496179, -0.46335426148862174, -0.02633009725195505], 'bias': 0.2676336062123419, 'activation': 0, 'error': 0.29463860360362987}], [{'weights': [0.29995068637477473, 0.3588487385403588, 0.1682166957356052, -0.4193521905606884, -0.4257863713775537], 'bias': -0.15625408839192734, 'activation': 0.5305984931021436, 'error': -0.5321055060318913}, {'weights': [-0.41656344463162415, -0.06289643213901569, 0.3562770305621547, -0.2258098916615354, 0.2089491784465131], 'bias': -0.29033269689943275, 'activation': 0.4694015068978564, 'error': 0.5321055060318913}]]\n",
      "\n",
      "========== BP ============\n",
      "Cross Entropy Loss des Output layers: 0.633749677270952\n",
      "\n",
      " ---------- Layer 3 ---------- \n",
      "\n",
      "Error: 0.4694015068978564\n",
      "Gradients of neuron Nr.0: [0.1321528410022631, 0.1321528410022631, 0.1321528410022631, 0.1321528410022631, 0.1321528410022631]\n",
      "Die weights: [0.29995068637477473, 0.3588487385403588, 0.1682166957356052, -0.4193521905606884, -0.4257863713775537] werden mit den weights [0.2986291579647521, 0.35752721013033617, 0.16689516732558254, -0.42067371897071104, -0.42710789978757635] ersetzt!\n",
      "der Bias: -0.15625408839192734 wird mit -0.1609481034609059 ersetzt!\n",
      "Error: -0.4694015068978564\n",
      "Gradients of neuron Nr.1: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [-0.41656344463162415, -0.06289643213901569, 0.3562770305621547, -0.2258098916615354, 0.2089491784465131] werden mit den weights [-0.41656344463162415, -0.06289643213901569, 0.3562770305621547, -0.2258098916615354, 0.2089491784465131] ersetzt!\n",
      "der Bias: -0.29033269689943275 wird mit -0.2856386818304542 ersetzt!\n",
      "\n",
      " ---------- Layer 2 ---------- \n",
      "\n",
      "Error: 0.188765447198127\n",
      "Gradients of neuron Nr.0: [0.00618393850889277, 0.00618393850889277, 0.00618393850889277, 0.00618393850889277, 0.00618393850889277]\n",
      "Die weights: [0.27779885104226926, -0.48726424951281117, 0.4323629981641555, 0.10896055465988391, 0.003976739097220222] werden mit den weights [0.27773701165718034, -0.4873260888979001, 0.4323011587790666, 0.10889871527479499, 0.003914899712131294] ersetzt!\n",
      "der Bias: 0.42000886539078 wird mit 0.4181212109187987 ersetzt!\n",
      "Error: 0.0\n",
      "Gradients of neuron Nr.1: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852] werden mit den weights [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852] ersetzt!\n",
      "der Bias: -0.39195604157641695 wird mit -0.39195604157641695 ersetzt!\n",
      "Error: -0.3517599624051851\n",
      "Gradients of neuron Nr.2: [-0.004527852286219429, -0.004527852286219429, -0.004527852286219429, -0.004527852286219429, -0.004527852286219429]\n",
      "Die weights: [0.45724510241340854, -0.28503818264792324, -0.15803030460662176, 0.08132335953420089, -0.4726291493984809] werden mit den weights [0.4572903809362707, -0.28499290412506106, -0.15798502608375956, 0.08136863805706308, -0.4725838708756187] ersetzt!\n",
      "der Bias: 0.3567979477033839 wird mit 0.36031554732743576 ersetzt!\n",
      "Error: -0.43964582066962254\n",
      "Gradients of neuron Nr.3: [-0.007227773498607349, -0.007227773498607349, -0.007227773498607349, -0.007227773498607349, -0.007227773498607349]\n",
      "Die weights: [0.005473609217919813, -0.053070644286848746, -0.1535562071896734, 0.2688603265470929, -0.010550530746356061] werden mit den weights [0.005545886952905887, -0.05299836655186267, -0.1534839294546873, 0.268932604282079, -0.010478253011369988] ersetzt!\n",
      "der Bias: 0.3834499349685605 wird mit 0.3878463931752567 ersetzt!\n",
      "Error: -0.0\n",
      "Gradients of neuron Nr.4: [-0.0, -0.0, -0.0, -0.0, -0.0]\n",
      "Die weights: [-0.4457121350801702, -0.37459554906959075, 0.4317439270496179, -0.46335426148862174, -0.02633009725195505] werden mit den weights [-0.4457121350801702, -0.37459554906959075, 0.4317439270496179, -0.46335426148862174, -0.02633009725195505] ersetzt!\n",
      "der Bias: 0.2676336062123419 wird mit 0.2676336062123419 ersetzt!\n",
      "\n",
      " ---------- Layer 1 ---------- \n",
      "\n",
      "Error: -0.33411792209393293\n",
      "Gradients of neuron Nr.0: [-0.004292100383790288, -0.004292100383790288, -0.004292100383790288, -0.004292100383790288, -0.004292100383790288, -0.004292100383790288, -0.004292100383790288, -0.004292100383790288, -0.004292100383790288]\n",
      "Die weights: [-0.205456225706411, 0.2204063342494715, -0.21665063604756832, 0.1659527683533106, 0.09818679356569267, -0.39337431236037973, -0.49478219330575596, -0.36621255687532933, 0.15030403356522978] werden mit den weights [-0.2054133047025731, 0.2204492552533094, -0.21660771504373041, 0.1659956893571485, 0.09822971456953057, -0.3933313913565418, -0.49473927230191805, -0.36616963587149143, 0.1503469545690677] ersetzt!\n",
      "der Bias: 0.35248515051710183 wird mit 0.3558263297380412 ersetzt!\n",
      "Error: -0.6561179585546064\n",
      "Gradients of neuron Nr.1: [0.004661224005018161, 0.004661224005018161, 0.004661224005018161, 0.004661224005018161, 0.004661224005018161, 0.004661224005018161, 0.004661224005018161, 0.004661224005018161, 0.004661224005018161]\n",
      "Die weights: [0.05348024521963981, -0.4604631637491343, 0.36344752218036525, 0.0891765766899555, 0.21233536503426123, 0.024400153801501095, 0.08451377977021214, 0.19313967812374636, -0.26765944533142316] werden mit den weights [0.053433632979589626, -0.4605097759891845, 0.36340090994031504, 0.08912996444990533, 0.21228875279421106, 0.024353541561450913, 0.08446716753016197, 0.19309306588369618, -0.26770605757147337] ersetzt!\n",
      "der Bias: 0.3617651395243815 wird mit 0.3683263191099276 ersetzt!\n",
      "Error: 0.0\n",
      "Gradients of neuron Nr.2: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [0.1671374941878093, 0.3153887892481055, 0.4584270012551343, -0.08746913363418887, -0.25610813822262063, -0.1412420572992437, 0.4225674975605475, -0.16631884610843142, -0.0033707542735464126] werden mit den weights [0.1671374941878093, 0.3153887892481055, 0.4584270012551343, -0.08746913363418887, -0.25610813822262063, -0.1412420572992437, 0.4225674975605475, -0.16631884610843142, -0.0033707542735464126] ersetzt!\n",
      "der Bias: -0.40101905211295064 wird mit -0.40101905211295064 ersetzt!\n",
      "Error: -0.0\n",
      "Gradients of neuron Nr.3: [-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0]\n",
      "Die weights: [-0.45434995956879254, -0.17013164777336642, 0.4923419279531569, -0.25803266100139555, 0.06125666067463662, 0.02886740273627096, 0.0697334639336885, -0.45558155488341323, 0.022957857812277646] werden mit den weights [-0.45434995956879254, -0.17013164777336642, 0.4923419279531569, -0.25803266100139555, 0.06125666067463662, 0.02886740273627096, 0.0697334639336885, -0.45558155488341323, 0.022957857812277646] ersetzt!\n",
      "der Bias: -0.4498036763391735 wird mit -0.4498036763391735 ersetzt!\n",
      "Error: 0.0\n",
      "Gradients of neuron Nr.4: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885] werden mit den weights [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885] ersetzt!\n",
      "der Bias: -0.3097403323387301 wird mit -0.3097403323387301 ersetzt!\n",
      "\n",
      " ---------- Layer 0 ---------- \n",
      "\n",
      "Netzwerk3: [[{'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}], [{'weights': [-0.2054133047025731, 0.2204492552533094, -0.21660771504373041, 0.1659956893571485, 0.09822971456953057, -0.3933313913565418, -0.49473927230191805, -0.36616963587149143, 0.1503469545690677], 'bias': 0.35248515051710183, 'activation': 0.22325040007572539, 'error': -0.33411792209393293}, {'weights': [0.053433632979589626, -0.4605097759891845, 0.36340090994031504, 0.08912996444990533, 0.21228875279421106, 0.024353541561450913, 0.08446716753016197, 0.19309306588369618, -0.26770605757147337], 'bias': 0.3617651395243815, 'activation': 0.6876772350500993, 'error': -0.6561179585546064}, {'weights': [0.1671374941878093, 0.3153887892481055, 0.4584270012551343, -0.08746913363418887, -0.25610813822262063, -0.1412420572992437, 0.4225674975605475, -0.16631884610843142, -0.0033707542735464126], 'bias': -0.40101905211295064, 'activation': 0, 'error': 0.0}, {'weights': [-0.45434995956879254, -0.17013164777336642, 0.4923419279531569, -0.25803266100139555, 0.06125666067463662, 0.02886740273627096, 0.0697334639336885, -0.45558155488341323, 0.022957857812277646], 'bias': -0.4498036763391735, 'activation': 0, 'error': -0.0}, {'weights': [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885], 'bias': -0.3097403323387301, 'activation': 0, 'error': 0.0}], [{'weights': [0.27773701165718034, -0.4873260888979001, 0.4323011587790666, 0.10889871527479499, 0.003914899712131294], 'bias': 0.42000886539078, 'activation': 0.1469470381828118, 'error': 0.188765447198127}, {'weights': [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852], 'bias': -0.39195604157641695, 'activation': 0, 'error': 0.0}, {'weights': [0.4572903809362707, -0.28499290412506106, -0.15798502608375956, 0.08136863805706308, -0.4725838708756187], 'bias': 0.3567979477033839, 'activation': 0.26286383042281436, 'error': -0.3517599624051851}, {'weights': [0.005545886952905887, -0.05299836655186267, -0.1534839294546873, 0.268932604282079, -0.010478253011369988], 'bias': 0.3834499349685605, 'activation': 0.3481764464908118, 'error': -0.43964582066962254}, {'weights': [-0.4457121350801702, -0.37459554906959075, 0.4317439270496179, -0.46335426148862174, -0.02633009725195505], 'bias': 0.2676336062123419, 'activation': 0, 'error': -0.0}], [{'weights': [0.2986291579647521, 0.35752721013033617, 0.16689516732558254, -0.42067371897071104, -0.42710789978757635], 'bias': -0.15625408839192734, 'activation': 0.5305984931021436, 'error': 0.4694015068978564}, {'weights': [-0.41656344463162415, -0.06289643213901569, 0.3562770305621547, -0.2258098916615354, 0.2089491784465131], 'bias': -0.29033269689943275, 'activation': 0.4694015068978564, 'error': -0.4694015068978564}]]\n",
      "**Iteration 9**\n",
      "\n",
      "========== FP ============\n",
      "Prediction: horizontal\n",
      "Netzwerk2: [[{'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}], [{'weights': [-0.2054133047025731, 0.2204492552533094, -0.21660771504373041, 0.1659956893571485, 0.09822971456953057, -0.3933313913565418, -0.49473927230191805, -0.36616963587149143, 0.1503469545690677], 'bias': 0.35248515051710183, 'activation': 0.15091338602410773, 'error': -0.33411792209393293}, {'weights': [0.053433632979589626, -0.4605097759891845, 0.36340090994031504, 0.08912996444990533, 0.21228875279421106, 0.024353541561450913, 0.08446716753016197, 0.19309306588369618, -0.26770605757147337], 'bias': 0.3617651395243815, 'activation': 0.31808990645510166, 'error': -0.6561179585546064}, {'weights': [0.1671374941878093, 0.3153887892481055, 0.4584270012551343, -0.08746913363418887, -0.25610813822262063, -0.1412420572992437, 0.4225674975605475, -0.16631884610843142, -0.0033707542735464126], 'bias': -0.40101905211295064, 'activation': 0.5399342325780985, 'error': 0.0}, {'weights': [-0.45434995956879254, -0.17013164777336642, 0.4923419279531569, -0.25803266100139555, 0.06125666067463662, 0.02886740273627096, 0.0697334639336885, -0.45558155488341323, 0.022957857812277646], 'bias': -0.4498036763391735, 'activation': 0, 'error': -0.0}, {'weights': [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885], 'bias': -0.3097403323387301, 'activation': 0, 'error': 0.0}], [{'weights': [0.27773701165718034, -0.4873260888979001, 0.4323011587790666, 0.10889871527479499, 0.003914899712131294], 'bias': 0.42000886539078, 'activation': 0.5403237826215166, 'error': 0.188765447198127}, {'weights': [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852], 'bias': -0.39195604157641695, 'activation': 0, 'error': 0.0}, {'weights': [0.4572903809362707, -0.28499290412506106, -0.15798502608375956, 0.08136863805706308, -0.4725838708756187], 'bias': 0.3567979477033839, 'activation': 0.24985429745585658, 'error': -0.3517599624051851}, {'weights': [0.005545886952905887, -0.05299836655186267, -0.1534839294546873, 0.268932604282079, -0.010478253011369988], 'bias': 0.3834499349685605, 'activation': 0.2845574104251877, 'error': -0.43964582066962254}, {'weights': [-0.4457121350801702, -0.37459554906959075, 0.4317439270496179, -0.46335426148862174, -0.02633009725195505], 'bias': 0.2676336062123419, 'activation': 0.31432794147510534, 'error': -0.0}], [{'weights': [0.2986291579647521, 0.35752721013033617, 0.16689516732558254, -0.42067371897071104, -0.42710789978757635], 'bias': -0.15625408839192734, 'activation': 0.5542396874632409, 'error': 0.4694015068978564}, {'weights': [-0.41656344463162415, -0.06289643213901569, 0.3562770305621547, -0.2258098916615354, 0.2089491784465131], 'bias': -0.29033269689943275, 'activation': 0.4457603125367591, 'error': -0.4694015068978564}]]\n",
      "\n",
      "========== BP ============\n",
      "Cross Entropy Loss des Output layers: 0.5901580369497654\n",
      "\n",
      " ---------- Layer 3 ---------- \n",
      "\n",
      "Error: 0.4457603125367591\n",
      "Gradients of neuron Nr.0: [0.13692937991114373, 0.13692937991114373, 0.13692937991114373, 0.13692937991114373, 0.13692937991114373]\n",
      "Die weights: [0.2986291579647521, 0.35752721013033617, 0.16689516732558254, -0.42067371897071104, -0.42710789978757635] werden mit den weights [0.29725986416564065, 0.35615791633122473, 0.1655258735264711, -0.4220430127698225, -0.4284771935866878] ersetzt!\n",
      "der Bias: -0.15625408839192734 wird mit -0.16071169151729492 ersetzt!\n",
      "Error: -0.4457603125367591\n",
      "Gradients of neuron Nr.1: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [-0.41656344463162415, -0.06289643213901569, 0.3562770305621547, -0.2258098916615354, 0.2089491784465131] werden mit den weights [-0.41656344463162415, -0.06289643213901569, 0.3562770305621547, -0.2258098916615354, 0.2089491784465131] ersetzt!\n",
      "der Bias: -0.29033269689943275 wird mit -0.28587509377406517 ersetzt!\n",
      "\n",
      " ---------- Layer 2 ---------- \n",
      "\n",
      "Error: -0.22212968139602435\n",
      "Gradients of neuron Nr.0: [0.042702404147054944, 0.042702404147054944, 0.042702404147054944, 0.042702404147054944, 0.042702404147054944]\n",
      "Die weights: [0.27773701165718034, -0.4873260888979001, 0.4323011587790666, 0.10889871527479499, 0.003914899712131294] werden mit den weights [0.2773099876157098, -0.4877531129393706, 0.43187413473759606, 0.10847169123332444, 0.003487875670660745] ersetzt!\n",
      "der Bias: 0.42000886539078 wird mit 0.4222301622047402 ersetzt!\n",
      "Error: 0.0\n",
      "Gradients of neuron Nr.1: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852] werden mit den weights [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852] ersetzt!\n",
      "der Bias: -0.39195604157641695 wird mit -0.39195604157641695 ersetzt!\n",
      "Error: -0.3348835928328313\n",
      "Gradients of neuron Nr.2: [-0.003981877114628112, -0.003981877114628112, -0.003981877114628112, -0.003981877114628112, -0.003981877114628112]\n",
      "Die weights: [0.4572903809362707, -0.28499290412506106, -0.15798502608375956, 0.08136863805706308, -0.4725838708756187] werden mit den weights [0.457330199707417, -0.2849530853539148, -0.15794520731261327, 0.08140845682820937, -0.4725440521044724] ersetzt!\n",
      "der Bias: 0.3567979477033839 wird mit 0.3601467836317122 ersetzt!\n",
      "Error: -0.3720303478204814\n",
      "Gradients of neuron Nr.3: [-0.005067436325001031, -0.005067436325001031, -0.005067436325001031, -0.005067436325001031, -0.005067436325001031]\n",
      "Die weights: [0.005545886952905887, -0.05299836655186267, -0.1534839294546873, 0.268932604282079, -0.010478253011369988] werden mit den weights [0.005596561316155897, -0.052947692188612665, -0.1534332550914373, 0.268983278645329, -0.010427578648119978] ersetzt!\n",
      "der Bias: 0.3834499349685605 wird mit 0.3871702384467653 ersetzt!\n",
      "Error: -0.5984673202917974\n",
      "Gradients of neuron Nr.4: [-0.019249251886576176, -0.019249251886576176, -0.019249251886576176, -0.019249251886576176, -0.019249251886576176]\n",
      "Die weights: [-0.4457121350801702, -0.37459554906959075, 0.4317439270496179, -0.46335426148862174, -0.02633009725195505] werden mit den weights [-0.44551964256130444, -0.374403056550725, 0.43193641956848366, -0.46316176896975597, -0.02613760473308929] ersetzt!\n",
      "der Bias: 0.2676336062123419 wird mit 0.27361827941525985 ersetzt!\n",
      "\n",
      " ---------- Layer 1 ---------- \n",
      "\n",
      "Error: -0.10111768964212174\n",
      "Gradients of neuron Nr.0: [0.0009629402303055135, 0.0009629402303055135, 0.0009629402303055135, 0.0009629402303055135, 0.0009629402303055135, 0.0009629402303055135, 0.0009629402303055135, 0.0009629402303055135, 0.0009629402303055135]\n",
      "Die weights: [-0.2054133047025731, 0.2204492552533094, -0.21660771504373041, 0.1659956893571485, 0.09822971456953057, -0.3933313913565418, -0.49473927230191805, -0.36616963587149143, 0.1503469545690677] werden mit den weights [-0.20542293410487616, 0.22043962585100635, -0.21661734444603348, 0.16598605995484544, 0.09822008516722752, -0.39334102075884486, -0.4947489017042211, -0.36617926527379446, 0.15033732516676462] ersetzt!\n",
      "der Bias: 0.35248515051710183 wird mit 0.35349632741352305 ersetzt!\n",
      "Error: 0.12944679243835128\n",
      "Gradients of neuron Nr.1: [0.0308784541087521, 0.0308784541087521, 0.0308784541087521, 0.0308784541087521, 0.0308784541087521, 0.0308784541087521, 0.0308784541087521, 0.0308784541087521, 0.0308784541087521]\n",
      "Die weights: [0.053433632979589626, -0.4605097759891845, 0.36340090994031504, 0.08912996444990533, 0.21228875279421106, 0.024353541561450913, 0.08446716753016197, 0.19309306588369618, -0.26770605757147337] werden mit den weights [0.053124848438502105, -0.46081856053027204, 0.3630921253992275, 0.08882117990881781, 0.21197996825312354, 0.02404475702036339, 0.08415838298907445, 0.19278428134260867, -0.2680148421125609] ersetzt!\n",
      "der Bias: 0.3617651395243815 wird mit 0.36047067159999796 ersetzt!\n",
      "Error: -0.7843910423316578\n",
      "Gradients of neuron Nr.2: [-0.03278715891685012, -0.03278715891685012, -0.03278715891685012, -0.03278715891685012, -0.03278715891685012, -0.03278715891685012, -0.03278715891685012, -0.03278715891685012, -0.03278715891685012]\n",
      "Die weights: [0.1671374941878093, 0.3153887892481055, 0.4584270012551343, -0.08746913363418887, -0.25610813822262063, -0.1412420572992437, 0.4225674975605475, -0.16631884610843142, -0.0033707542735464126] werden mit den weights [0.1674653657769778, 0.315716660837274, 0.45875487284430283, -0.08714126204502037, -0.2557802666334521, -0.1409141857100752, 0.42289536914971604, -0.16599097451926292, -0.0030428826843779113] ersetzt!\n",
      "der Bias: -0.40101905211295064 wird mit -0.3931751416896341 ersetzt!\n",
      "Error: 0.0\n",
      "Gradients of neuron Nr.3: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [-0.45434995956879254, -0.17013164777336642, 0.4923419279531569, -0.25803266100139555, 0.06125666067463662, 0.02886740273627096, 0.0697334639336885, -0.45558155488341323, 0.022957857812277646] werden mit den weights [-0.45434995956879254, -0.17013164777336642, 0.4923419279531569, -0.25803266100139555, 0.06125666067463662, 0.02886740273627096, 0.0697334639336885, -0.45558155488341323, 0.022957857812277646] ersetzt!\n",
      "der Bias: -0.4498036763391735 wird mit -0.4498036763391735 ersetzt!\n",
      "Error: 0.0\n",
      "Gradients of neuron Nr.4: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885] werden mit den weights [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885] ersetzt!\n",
      "der Bias: -0.3097403323387301 wird mit -0.3097403323387301 ersetzt!\n",
      "\n",
      " ---------- Layer 0 ---------- \n",
      "\n",
      "Netzwerk3: [[{'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}], [{'weights': [-0.20542293410487616, 0.22043962585100635, -0.21661734444603348, 0.16598605995484544, 0.09822008516722752, -0.39334102075884486, -0.4947489017042211, -0.36617926527379446, 0.15033732516676462], 'bias': 0.35248515051710183, 'activation': 0.15091338602410773, 'error': -0.10111768964212174}, {'weights': [0.053124848438502105, -0.46081856053027204, 0.3630921253992275, 0.08882117990881781, 0.21197996825312354, 0.02404475702036339, 0.08415838298907445, 0.19278428134260867, -0.2680148421125609], 'bias': 0.3617651395243815, 'activation': 0.31808990645510166, 'error': 0.12944679243835128}, {'weights': [0.1674653657769778, 0.315716660837274, 0.45875487284430283, -0.08714126204502037, -0.2557802666334521, -0.1409141857100752, 0.42289536914971604, -0.16599097451926292, -0.0030428826843779113], 'bias': -0.40101905211295064, 'activation': 0.5399342325780985, 'error': -0.7843910423316578}, {'weights': [-0.45434995956879254, -0.17013164777336642, 0.4923419279531569, -0.25803266100139555, 0.06125666067463662, 0.02886740273627096, 0.0697334639336885, -0.45558155488341323, 0.022957857812277646], 'bias': -0.4498036763391735, 'activation': 0, 'error': 0.0}, {'weights': [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885], 'bias': -0.3097403323387301, 'activation': 0, 'error': 0.0}], [{'weights': [0.2773099876157098, -0.4877531129393706, 0.43187413473759606, 0.10847169123332444, 0.003487875670660745], 'bias': 0.42000886539078, 'activation': 0.5403237826215166, 'error': -0.22212968139602435}, {'weights': [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852], 'bias': -0.39195604157641695, 'activation': 0, 'error': 0.0}, {'weights': [0.457330199707417, -0.2849530853539148, -0.15794520731261327, 0.08140845682820937, -0.4725440521044724], 'bias': 0.3567979477033839, 'activation': 0.24985429745585658, 'error': -0.3348835928328313}, {'weights': [0.005596561316155897, -0.052947692188612665, -0.1534332550914373, 0.268983278645329, -0.010427578648119978], 'bias': 0.3834499349685605, 'activation': 0.2845574104251877, 'error': -0.3720303478204814}, {'weights': [-0.44551964256130444, -0.374403056550725, 0.43193641956848366, -0.46316176896975597, -0.02613760473308929], 'bias': 0.2676336062123419, 'activation': 0.31432794147510534, 'error': -0.5984673202917974}], [{'weights': [0.29725986416564065, 0.35615791633122473, 0.1655258735264711, -0.4220430127698225, -0.4284771935866878], 'bias': -0.15625408839192734, 'activation': 0.5542396874632409, 'error': 0.4457603125367591}, {'weights': [-0.41656344463162415, -0.06289643213901569, 0.3562770305621547, -0.2258098916615354, 0.2089491784465131], 'bias': -0.29033269689943275, 'activation': 0.4457603125367591, 'error': -0.4457603125367591}]]\n",
      "**Iteration 10**\n",
      "\n",
      "========== FP ============\n",
      "Prediction: horizontal\n",
      "Netzwerk2: [[{'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}], [{'weights': [-0.20542293410487616, 0.22043962585100635, -0.21661734444603348, 0.16598605995484544, 0.09822008516722752, -0.39334102075884486, -0.4947489017042211, -0.36617926527379446, 0.15033732516676462], 'bias': 0.35248515051710183, 'activation': 0, 'error': -0.10111768964212174}, {'weights': [0.053124848438502105, -0.46081856053027204, 0.3630921253992275, 0.08882117990881781, 0.21197996825312354, 0.02404475702036339, 0.08415838298907445, 0.19278428134260867, -0.2680148421125609], 'bias': 0.3617651395243815, 'activation': 0.48088717983141155, 'error': 0.12944679243835128}, {'weights': [0.1674653657769778, 0.315716660837274, 0.45875487284430283, -0.08714126204502037, -0.2557802666334521, -0.1409141857100752, 0.42289536914971604, -0.16599097451926292, -0.0030428826843779113], 'bias': -0.40101905211295064, 'activation': 0, 'error': -0.7843910423316578}, {'weights': [-0.45434995956879254, -0.17013164777336642, 0.4923419279531569, -0.25803266100139555, 0.06125666067463662, 0.02886740273627096, 0.0697334639336885, -0.45558155488341323, 0.022957857812277646], 'bias': -0.4498036763391735, 'activation': 0.09436351216253203, 'error': 0.0}, {'weights': [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885], 'bias': -0.3097403323387301, 'activation': 0, 'error': 0.0}], [{'weights': [0.2773099876157098, -0.4877531129393706, 0.43187413473759606, 0.10847169123332444, 0.003487875670660745], 'bias': 0.42000886539078, 'activation': 0.1956904162103603, 'error': -0.22212968139602435}, {'weights': [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852], 'bias': -0.39195604157641695, 'activation': 0, 'error': 0.0}, {'weights': [0.457330199707417, -0.2849530853539148, -0.15794520731261327, 0.08140845682820937, -0.4725440521044724], 'bias': 0.3567979477033839, 'activation': 0.22744965000932202, 'error': -0.3348835928328313}, {'weights': [0.005596561316155897, -0.052947692188612665, -0.1534332550914373, 0.268983278645329, -0.010427578648119978], 'bias': 0.3834499349685605, 'activation': 0.38337027547936314, 'error': -0.3720303478204814}, {'weights': [-0.44551964256130444, -0.374403056550725, 0.43193641956848366, -0.46316176896975597, -0.02613760473308929], 'bias': 0.2676336062123419, 'activation': 0.04388240500800583, 'error': -0.5984673202917974}], [{'weights': [0.29725986416564065, 0.35615791633122473, 0.1655258735264711, -0.4220430127698225, -0.4284771935866878], 'bias': -0.15625408839192734, 'activation': 0.5317519531734692, 'error': 0.4457603125367591}, {'weights': [-0.41656344463162415, -0.06289643213901569, 0.3562770305621547, -0.2258098916615354, 0.2089491784465131], 'bias': -0.29033269689943275, 'activation': 0.4682480468265308, 'error': -0.4457603125367591}]]\n",
      "\n",
      "========== BP ============\n",
      "Cross Entropy Loss des Output layers: 0.758757108886007\n",
      "\n",
      " ---------- Layer 3 ---------- \n",
      "\n",
      "Error: -0.5317519531734692\n",
      "Gradients of neuron Nr.0: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [0.29725986416564065, 0.35615791633122473, 0.1655258735264711, -0.4220430127698225, -0.4284771935866878] werden mit den weights [0.29725986416564065, 0.35615791633122473, 0.1655258735264711, -0.4220430127698225, -0.4284771935866878] ersetzt!\n",
      "der Bias: -0.15625408839192734 wird mit -0.15093656886019263 ersetzt!\n",
      "Error: 0.5317519531734691\n",
      "Gradients of neuron Nr.1: [0.11658993033296876, 0.11658993033296876, 0.11658993033296876, 0.11658993033296876, 0.11658993033296876]\n",
      "Die weights: [-0.41656344463162415, -0.06289643213901569, 0.3562770305621547, -0.2258098916615354, 0.2089491784465131] werden mit den weights [-0.4177293439349538, -0.06406233144234538, 0.35511113125882504, -0.2269757909648651, 0.2077832791431834] ersetzt!\n",
      "der Bias: -0.29033269689943275 wird mit -0.29565021643116746 ersetzt!\n",
      "\n",
      " ---------- Layer 2 ---------- \n",
      "\n",
      "Error: -0.5758873241158035\n",
      "Gradients of neuron Nr.0: [-0.01171037864784825, -0.01171037864784825, -0.01171037864784825, -0.01171037864784825, -0.01171037864784825]\n",
      "Die weights: [0.2773099876157098, -0.4877531129393706, 0.43187413473759606, 0.10847169123332444, 0.003487875670660745] werden mit den weights [0.2774270914021883, -0.4876360091528921, 0.43199123852407456, 0.10858879501980293, 0.0036049794571392274] ersetzt!\n",
      "der Bias: 0.42000886539078 wird mit 0.425767738631938 ersetzt!\n",
      "Error: -0.0\n",
      "Gradients of neuron Nr.1: [-0.0, -0.0, -0.0, -0.0, -0.0]\n",
      "Die weights: [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852] werden mit den weights [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852] ersetzt!\n",
      "der Bias: -0.39195604157641695 wird mit -0.39195604157641695 ersetzt!\n",
      "Error: -0.12663731891724728\n",
      "Gradients of neuron Nr.2: [0.004029127368388256, 0.004029127368388256, 0.004029127368388256, 0.004029127368388256, 0.004029127368388256]\n",
      "Die weights: [0.457330199707417, -0.2849530853539148, -0.15794520731261327, 0.08140845682820937, -0.4725440521044724] werden mit den weights [0.4572899084337331, -0.28499337662759866, -0.15798549858629715, 0.08136816555452549, -0.4725843433781563] ersetzt!\n",
      "der Bias: 0.3567979477033839 wird mit 0.3580643208925564 ersetzt!\n",
      "Error: -0.2796428992844547\n",
      "Gradients of neuron Nr.3: [0.009400581572376493, 0.009400581572376493, 0.009400581572376493, 0.009400581572376493, 0.009400581572376493]\n",
      "Die weights: [0.005596561316155897, -0.052947692188612665, -0.1534332550914373, 0.268983278645329, -0.010427578648119978] werden mit den weights [0.0055025555004321325, -0.05304169800433643, -0.15352726090716107, 0.26888927282960523, -0.010521584463843743] ersetzt!\n",
      "der Bias: 0.3834499349685605 wird mit 0.38624636396140505 ersetzt!\n",
      "Error: 0.294450344093178\n",
      "Gradients of neuron Nr.4: [0.0006229256166043579, 0.0006229256166043579, 0.0006229256166043579, 0.0006229256166043579, 0.0006229256166043579]\n",
      "Die weights: [-0.44551964256130444, -0.374403056550725, 0.43193641956848366, -0.46316176896975597, -0.02613760473308929] werden mit den weights [-0.4455258718174705, -0.37440928580689103, 0.4319301903123176, -0.46316799822592203, -0.026143833989255332] ersetzt!\n",
      "der Bias: 0.2676336062123419 wird mit 0.2646891027714101 ersetzt!\n",
      "\n",
      " ---------- Layer 1 ---------- \n",
      "\n",
      "Error: -0.0\n",
      "Gradients of neuron Nr.0: [-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0]\n",
      "Die weights: [-0.20542293410487616, 0.22043962585100635, -0.21661734444603348, 0.16598605995484544, 0.09822008516722752, -0.39334102075884486, -0.4947489017042211, -0.36617926527379446, 0.15033732516676462] werden mit den weights [-0.20542293410487616, 0.22043962585100635, -0.21661734444603348, 0.16598605995484544, 0.09822008516722752, -0.39334102075884486, -0.4947489017042211, -0.36617926527379446, 0.15033732516676462] ersetzt!\n",
      "der Bias: 0.35248515051710183 wird mit 0.35248515051710183 ersetzt!\n",
      "Error: -0.25938519507716773\n",
      "Gradients of neuron Nr.1: [0.026590455375205636, 0.026590455375205636, 0.026590455375205636, 0.026590455375205636, 0.026590455375205636, 0.026590455375205636, 0.026590455375205636, 0.026590455375205636, 0.026590455375205636]\n",
      "Die weights: [0.053124848438502105, -0.46081856053027204, 0.3630921253992275, 0.08882117990881781, 0.21197996825312354, 0.02404475702036339, 0.08415838298907445, 0.19278428134260867, -0.2680148421125609] werden mit den weights [0.05285894388475005, -0.4610844650840241, 0.36282622084547544, 0.08855527535506576, 0.21171406369937149, 0.023778852466611336, 0.0838924784353224, 0.1925183767888566, -0.26828074666631296] ersetzt!\n",
      "der Bias: 0.3617651395243815 wird mit 0.36435899147515316 ersetzt!\n",
      "Error: -0.0\n",
      "Gradients of neuron Nr.2: [-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0]\n",
      "Die weights: [0.1674653657769778, 0.315716660837274, 0.45875487284430283, -0.08714126204502037, -0.2557802666334521, -0.1409141857100752, 0.42289536914971604, -0.16599097451926292, -0.0030428826843779113] werden mit den weights [0.1674653657769778, 0.315716660837274, 0.45875487284430283, -0.08714126204502037, -0.2557802666334521, -0.1409141857100752, 0.42289536914971604, -0.16599097451926292, -0.0030428826843779113] ersetzt!\n",
      "der Bias: -0.40101905211295064 wird mit -0.40101905211295064 ersetzt!\n",
      "Error: -0.3787756213776164\n",
      "Gradients of neuron Nr.3: [-0.0022935604358292954, -0.0022935604358292954, -0.0022935604358292954, -0.0022935604358292954, -0.0022935604358292954, -0.0022935604358292954, -0.0022935604358292954, -0.0022935604358292954, -0.0022935604358292954]\n",
      "Die weights: [-0.45434995956879254, -0.17013164777336642, 0.4923419279531569, -0.25803266100139555, 0.06125666067463662, 0.02886740273627096, 0.0697334639336885, -0.45558155488341323, 0.022957857812277646] werden mit den weights [-0.45432702396443425, -0.17010871216900814, 0.4923648635575152, -0.25800972539703726, 0.061279596278994916, 0.028890338340629255, 0.06975639953804678, -0.45555861927905494, 0.02298079341663594] ersetzt!\n",
      "der Bias: -0.4498036763391735 wird mit -0.44601592012539737 ersetzt!\n",
      "Error: 0.0\n",
      "Gradients of neuron Nr.4: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Die weights: [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885] werden mit den weights [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885] ersetzt!\n",
      "der Bias: -0.3097403323387301 wird mit -0.3097403323387301 ersetzt!\n",
      "\n",
      " ---------- Layer 0 ---------- \n",
      "\n",
      "Netzwerk3: [[{'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}], [{'weights': [-0.20542293410487616, 0.22043962585100635, -0.21661734444603348, 0.16598605995484544, 0.09822008516722752, -0.39334102075884486, -0.4947489017042211, -0.36617926527379446, 0.15033732516676462], 'bias': 0.35248515051710183, 'activation': 0, 'error': -0.0}, {'weights': [0.05285894388475005, -0.4610844650840241, 0.36282622084547544, 0.08855527535506576, 0.21171406369937149, 0.023778852466611336, 0.0838924784353224, 0.1925183767888566, -0.26828074666631296], 'bias': 0.3617651395243815, 'activation': 0.48088717983141155, 'error': -0.25938519507716773}, {'weights': [0.1674653657769778, 0.315716660837274, 0.45875487284430283, -0.08714126204502037, -0.2557802666334521, -0.1409141857100752, 0.42289536914971604, -0.16599097451926292, -0.0030428826843779113], 'bias': -0.40101905211295064, 'activation': 0, 'error': -0.0}, {'weights': [-0.45432702396443425, -0.17010871216900814, 0.4923648635575152, -0.25800972539703726, 0.061279596278994916, 0.028890338340629255, 0.06975639953804678, -0.45555861927905494, 0.02298079341663594], 'bias': -0.4498036763391735, 'activation': 0.09436351216253203, 'error': -0.3787756213776164}, {'weights': [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885], 'bias': -0.3097403323387301, 'activation': 0, 'error': 0.0}], [{'weights': [0.2774270914021883, -0.4876360091528921, 0.43199123852407456, 0.10858879501980293, 0.0036049794571392274], 'bias': 0.42000886539078, 'activation': 0.1956904162103603, 'error': -0.5758873241158035}, {'weights': [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852], 'bias': -0.39195604157641695, 'activation': 0, 'error': -0.0}, {'weights': [0.4572899084337331, -0.28499337662759866, -0.15798549858629715, 0.08136816555452549, -0.4725843433781563], 'bias': 0.3567979477033839, 'activation': 0.22744965000932202, 'error': -0.12663731891724728}, {'weights': [0.0055025555004321325, -0.05304169800433643, -0.15352726090716107, 0.26888927282960523, -0.010521584463843743], 'bias': 0.3834499349685605, 'activation': 0.38337027547936314, 'error': -0.2796428992844547}, {'weights': [-0.4455258718174705, -0.37440928580689103, 0.4319301903123176, -0.46316799822592203, -0.026143833989255332], 'bias': 0.2676336062123419, 'activation': 0.04388240500800583, 'error': 0.294450344093178}], [{'weights': [0.29725986416564065, 0.35615791633122473, 0.1655258735264711, -0.4220430127698225, -0.4284771935866878], 'bias': -0.15625408839192734, 'activation': 0.5317519531734692, 'error': -0.5317519531734692}, {'weights': [-0.4177293439349538, -0.06406233144234538, 0.35511113125882504, -0.2269757909648651, 0.2077832791431834], 'bias': -0.29033269689943275, 'activation': 0.4682480468265308, 'error': 0.5317519531734691}]]\n",
      "Netzwerk2: [[{'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 0, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}, {'weights': None, 'bias': None, 'activation': 1, 'error': None}], [{'weights': [-0.20542293410487616, 0.22043962585100635, -0.21661734444603348, 0.16598605995484544, 0.09822008516722752, -0.39334102075884486, -0.4947489017042211, -0.36617926527379446, 0.15033732516676462], 'bias': 0.35248515051710183, 'activation': 0, 'error': -0.0}, {'weights': [0.05285894388475005, -0.4610844650840241, 0.36282622084547544, 0.08855527535506576, 0.21171406369937149, 0.023778852466611336, 0.0838924784353224, 0.1925183767888566, -0.26828074666631296], 'bias': 0.3617651395243815, 'activation': 0.36989524808224755, 'error': -0.25938519507716773}, {'weights': [0.1674653657769778, 0.315716660837274, 0.45875487284430283, -0.08714126204502037, -0.2557802666334521, -0.1409141857100752, 0.42289536914971604, -0.16599097451926292, -0.0030428826843779113], 'bias': -0.40101905211295064, 'activation': 0, 'error': -0.0}, {'weights': [-0.45432702396443425, -0.17010871216900814, 0.4923648635575152, -0.25800972539703726, 0.061279596278994916, 0.028890338340629255, 0.06975639953804678, -0.45555861927905494, 0.02298079341663594], 'bias': -0.4498036763391735, 'activation': 0, 'error': -0.3787756213776164}, {'weights': [-0.05189519453679954, 0.10462090821002895, -0.3773722717764635, 0.2756641982991981, -0.4566883279889028, -0.45818391070347697, 0.2399648704202509, 0.41847197360553934, 0.32945153155971885], 'bias': -0.3097403323387301, 'activation': 0.6781480432467789, 'error': 0.0}], [{'weights': [0.2774270914021883, -0.4876360091528921, 0.43199123852407456, 0.10858879501980293, 0.0036049794571392274], 'bias': 0.42000886539078, 'activation': 0.2420793325761376, 'error': -0.5758873241158035}, {'weights': [0.3643595251131492, -0.4722119508652616, -0.21617922406104362, -0.038839467390775484, -0.08468504987827852], 'bias': -0.39195604157641695, 'activation': 0, 'error': -0.0}, {'weights': [0.4572899084337331, -0.28499337662759866, -0.15798549858629715, 0.08136816555452549, -0.4725843433781563], 'bias': 0.3567979477033839, 'activation': 0, 'error': -0.12663731891724728}, {'weights': [0.0055025555004321325, -0.05304169800433643, -0.15352726090716107, 0.26888927282960523, -0.010521584463843743], 'bias': 0.3834499349685605, 'activation': 0.3566948710105315, 'error': -0.2796428992844547}, {'weights': [-0.4455258718174705, -0.37440928580689103, 0.4319301903123176, -0.46316799822592203, -0.026143833989255332], 'bias': 0.2676336062123419, 'activation': 0.11141200069172266, 'error': 0.294450344093178}], [{'weights': [0.29725986416564065, 0.35615791633122473, 0.1655258735264711, -0.4220430127698225, -0.4284771935866878], 'bias': -0.15625408839192734, 'activation': 0.5415778127872571, 'error': -0.5317519531734692}, {'weights': [-0.4177293439349538, -0.06406233144234538, 0.35511113125882504, -0.2269757909648651, 0.2077832791431834], 'bias': -0.29033269689943275, 'activation': 0.45842218721274275, 'error': 0.5317519531734691}]]\n",
      "Prediction: Die Prediction hat eine komische Form und ergibt nicht 1 in der Summe!\n"
     ]
    }
   ],
   "source": [
    "# den gesamten ableuf um das model zu trainieren\n",
    "'''\n",
    "input:\n",
    "- ein pixelbild (in doeser form mus es sein: ...)\n",
    "- die prediction fÃ¼r dieses pixelbild (in dieser form muss das sein: ...)\n",
    "'''\n",
    "\n",
    "def target_converter(target):\n",
    "    if target == 1:\n",
    "        target = [1, 0]\n",
    "    else:\n",
    "        target = [0, 1]\n",
    "\n",
    "    return target\n",
    "\n",
    "# initialisiertes netzwerk\n",
    "with open(file_path_ni, \"r\") as file:\n",
    "    nn_i = json.load(file)\n",
    "\n",
    "# trainingsdaten\n",
    "with open(file_path_dt, \"r\") as file:\n",
    "    data_train = json.load(file)\n",
    "\n",
    "# alle benÃ¶rigten daten werden aus den jsons geholt!\n",
    "print(\"\\n======== DATA ========\") \n",
    "pixelbild = data_train[0][0] # ein beispiel der trainingsdaten\n",
    "target = data_train[0][1]\n",
    "print(f\"Pixelbild: {pixelbild}, Target: {target}\")\n",
    "nn = nn_i # initialisiertes netzwerk vom json-file holen\n",
    "print(f\"Netzwerk1: {nn}\")\n",
    "\n",
    "\n",
    "def train(nn1, input, target):\n",
    "\n",
    "    target = target_converter(target)\n",
    "\n",
    "    print(\"\\n========== FP ============\")\n",
    "    # forward-propagation:\n",
    "    nn2, last_activations = forward_propagation(input, nn1)\n",
    "    prediction = predict(last_activations)\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "    print(f\"Netzwerk2: {nn2}\")\n",
    "\n",
    "    # loss-funktion: wie gut ist die prediction? -> dise wird innerhalb der backprop gemacht\n",
    "\n",
    "    print(\"\\n========== BP ============\")\n",
    "    # backward-propagation:\n",
    "    nn3 = backprop(nn2, target, 0.01)\n",
    "    print(f\"Netzwerk3: {nn3}\")\n",
    "\n",
    "    return nn3\n",
    "\n",
    "#train(nn, pixelbild, target)\n",
    "\n",
    "# mehrere iterationen von trainieren! (loop mit train machen)\n",
    "def train_iterations(nn1, data_train):\n",
    "    nn3_list = []\n",
    "    for index in range(len(data_train)):\n",
    "        print(f\"**Iteration {index+1}**\")\n",
    "        nn3 = train(nn1, data_train[index][0], data_train[index][1])\n",
    "        nn3_list.append(nn3)\n",
    "        nn1 = nn3 # nach jeder iteration muss man als neues input-netzwerk das neu kreierte definieren\n",
    "\n",
    "    return nn3_list\n",
    "\n",
    "nn3_list = train_iterations(nn, data_train)\n",
    "nn_pretrained = nn3_list[-1]\n",
    "\n",
    "\n",
    "# hier wird die forward-prop gemacht und kein trainigng mit prediction und allem...\n",
    "# diese funktion ruft man mit einem netzwerk auf welches beretis trainiert wurde! fÃ¼r den inut nutzt man trainingsdaten!\n",
    "def test(nn1, input):\n",
    "    nn2, last_activations = forward_propagation(input, nn1)\n",
    "    print(f\"Netzwerk2: {nn2}\")\n",
    "    prediction = predict(last_activations)\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "\n",
    "test(nn_pretrained, pixelbild)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# am ende der trainingsrunde das neuste ud beste modell dem json hineintun und mit dem alten somit ersetzen\n",
    "file_path_n = \"../model/netzwerk.json\"\n",
    "with open(file_path_n, \"w\") as file:\n",
    "    json.dump(nn_pretrained, file, indent=4)\n",
    "\n",
    "# die liste mit allen modellen aller trainingsrunden ins json laden\n",
    "file_path_nh = \"../model/netzwerk_history.json\"\n",
    "with open(file_path_nh, \"w\") as file:\n",
    "    json.dump(nn3_list, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
